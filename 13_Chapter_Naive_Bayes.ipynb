{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter, defaultdict\n",
    "from machine_learning import split_data\n",
    "import math, random, re, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSciencester has a popular feature that allows members to send messages to other members.  \n",
    "The VP of DataSciencester has tasked you with building a spam filter for those messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Really Dumb Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember Bayes' Theorem?  \n",
    "\n",
    "${\\large\\displaystyle P(A\\mid B)={\\frac {P(B\\mid A)\\,P(A)}{P(B)}}}$  \n",
    "\n",
    "where A and B are events and P(B) â‰  0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine a 'universe' that consists of receiving a message chosen randomly from all possible messages.  \n",
    "Let **`S`** be the event \"the message is spam\" and **`V`** be the event \"the message contains the word *viagra*.\"  \n",
    "Bayes' Theorem tells us that the probability that the message is spam *conditional* on containing the word viagra is:  \n",
    "\n",
    "${\\large\\displaystyle P(S\\mid V)={\\frac {P(V\\mid S)\\,P(S)}{P(V\\mid S)\\,P(S) + P(V\\mid \\neg S)P(\\neg S)}}}$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerator is the probability that a message is spam *and* contains 'viagra', while the denominator is the probability that a message contains 'viagra'.  \n",
    "Think of this calculation as representing the proportion of 'viagra' messages that are spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a large corpus of messages that we know are spam, and a large collection of messages that we know are *not* spam, then we can estimate ${P(V\\mid S)}$ and ${P(V\\mid \\neg S)}$.  \n",
    "If we further assume that any message is equally likely to be spam or not-spam ( ${P(S) = 0.5}$ and ${P(\\neg S) = 0.5}$ ), then:  \n",
    "\n",
    "${\\large\\displaystyle P(S\\mid V)={\\frac {P(V\\mid S)\\,}{P(V\\mid S) + P(V\\mid \\neg S)}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if 50% of spam messages have the word *viagra*, but only 1% of nonspam messages do, then the probability that any given *viagra*-containing email is spam is:  \n",
    "\n",
    "${\\large\\displaystyle {\\frac {0.5}{0.5 \\,+\\, 0.01} = {98\\%}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A More Sophisticated Spam Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
