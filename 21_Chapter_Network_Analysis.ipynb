{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21. Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math, random, re\n",
    "from collections import defaultdict, Counter, deque\n",
    "from linear_algebra import dot, get_row, get_column, make_matrix, magnitude, scalar_multiply, shape, distance\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many interesting data problems can be thought of in terms of [networks](https://en.wikipedia.org/wiki/Network_theory) consisting of nodes of some type and the edges that join them (see [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) and [graph theory](https://en.wikipedia.org/wiki/Graph_theory) for more information on nodes and edges).  \n",
    "For example, your Facebook friends form the nodes of a network whose edges are friendship relations.  \n",
    "A less obvious example is the World Wide Web itself, with each web page a node, and each hyperlink from one page to another an edge.  \n",
    "Facebook friendship is mutual -- if I am Facebook friends with you then necessarily you are friends with me.  \n",
    "In this case, we say that the edges are [undirected](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29#Undirected_graph).  \n",
    "Hyperlinks are not -- a website $A$ may link to website $Z$ without $Z$ linking to $A$.  \n",
    "We call these types of edges [directed](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29#Directed_graph).  \n",
    "We'll be dealing with both kinds of networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweenness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 1, we calculated the key connectors in the DataSciencester network by counting the number of friends that each user had.  \n",
    "Now we have enough machinery to look at other approaches.  \n",
    "Recall that the network comprised users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = [\n",
    "    { \"id\": 0, \"name\": \"Hero\" },\n",
    "    { \"id\": 1, \"name\": \"Dunn\" },\n",
    "    { \"id\": 2, \"name\": \"Sue\" },\n",
    "    { \"id\": 3, \"name\": \"Chi\" },\n",
    "    { \"id\": 4, \"name\": \"Thor\" },\n",
    "    { \"id\": 5, \"name\": \"Clive\" },\n",
    "    { \"id\": 6, \"name\": \"Hicks\" },\n",
    "    { \"id\": 7, \"name\": \"Devin\" },\n",
    "    { \"id\": 8, \"name\": \"Kate\" },\n",
    "    { \"id\": 9, \"name\": \"Klein\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and friendships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "friendships = [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (3, 4),\n",
    "               (4, 5), (5, 6), (5, 7), (6, 8), (7, 8), (8, 9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our network looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![users_network_graph](img/users_network_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also added friend lists to each user `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user[\"friends\"] = []\n",
    "    \n",
    "for i, j in friendships:\n",
    "    # this works because users[i] is the user whose id is i \n",
    "    users[i][\"friends\"].append(users[j])  # add i as a friend of j\n",
    "    users[j][\"friends\"].append(users[i])  # add j as a friend of i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we left off we were dissatisfied with our notion of [degree centrality](https://en.wikipedia.org/wiki/Centrality#Degree_centrality), which didn't really agree with our intuition about who were the key connectors of the network.  \n",
    "An alternative metric is [betweenness centrality](https://en.wikipedia.org/wiki/Centrality#Betweenness_centrality), which identifies people who frequently are on the shortest paths between pairs of other people.  \n",
    "In particular, the betweenness centrality of node $i$ is computed by adding up, for every other pair of nodes $j$ and $k$, the proportion of shortest paths between node $j$ and node $k$ that pass through $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, to figure out Thor's betweenness centrality, we'll need to compute all of the shortest paths between all pairs of people who aren't Thor.  \n",
    "Then we'll need to count how many of those shortest paths pass through Thor.  \n",
    "For instance, the only shortest path between Chi (id 3) and Clive (id 5) passes through Thor, while neither of the shortest paths between Hero (id 0) and Chi (id 3) does.\n",
    "Therefore, as a first step, we'll need to figure out the shortest paths between all pairs of people.  \n",
    "There are some pretty sophisticated algorithms for doing so efficiently, but, because we're learning and building from scratch, we'll use a less efficient but more easily understood algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm, which is an implementation of [breadth-first search](https://en.wikipedia.org/wiki/Breadth-first_search), is one of the more complicated ones in this book, so let's go through it carefully:\n",
    "1. Our goal is a function that takes a `from_user` and finds *all* shortest paths to every other user.\n",
    "2. We'll represent a path as a `list` of user IDs. Since every path starts at `from_user`, we won't include her ID in the list. This means that the length of the list representing the path will be the length of the path itself.\n",
    "3. We'll maintain a dictionary `shortest_paths_to` where the keys are user IDs and the values are lists of paths that end at the user with the specified ID. If there is a unique shortest path, the list will just contain that one path. If there are multiple shortest paths, the list will contain all of them.\n",
    "4. We'll also maintain a [queue](https://en.wikipedia.org/wiki/Breadth-first_search) `frontier` that contains the users we want to explore in the order we want to explore them. (A queue is a data structure that is optimized for operations that \"add to the end\" and \"remove from the front\". In Python, they are implemented as [collections.deque](https://docs.python.org/2/library/collections.html#collections.deque) which is actually a double-ended queue.) We'll store them as pairs (`prev_user, user`) so that we know how we got to each one. We initialize the queue with all of the neighbors of `from_user`.\n",
    "5. As we explore the graph, whenever we find new neighbors that we don't already know the shortest paths to, we add them to the end of the queue to explore later, with the current user as `prev_user`.\n",
    "6. When we take a user off of the queue, and we've never encountered that user before, we've definitely found one or more shortest paths to him -- each of the shortest paths to `prev_user` with one extra step added.\n",
    "7. When we take a user off of the queue and we *have* encountered that user before, then either we've found another shortest path (in which case we should add it) or we've found a longer path (in which case we shouldn't).\n",
    "8. When no more users are left on the queue, we've explored the whole graph (or, at least. the parts of it that are reachable from the starting user) and we're done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can put all of this together into one, rather large, function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shortest_paths_from(from_user):\n",
    "    \n",
    "    # a dictionary from \"user_id\" to *all* shortest paths to that user\n",
    "    shortest_paths_to = { from_user[\"id\"] : [[]] }\n",
    "\n",
    "    # a queue of (previous user, next user) that we need to check.\n",
    "    # starts out with all pairs (from_user, friend_of_from_user)\n",
    "    frontier = deque((from_user, friend)\n",
    "                     for friend in from_user[\"friends\"])\n",
    "\n",
    "    # keep going until we empty the queue\n",
    "    while frontier: \n",
    "\n",
    "        prev_user, user = frontier.popleft() # take from the beginning\n",
    "        user_id = user[\"id\"]\n",
    "\n",
    "        # the fact that we're pulling from our queue means that\n",
    "        # necessarily we already know a shortest path to prev_user\n",
    "        paths_to_prev = shortest_paths_to[prev_user[\"id\"]]\n",
    "        paths_via_prev = [path + [user_id] for path in paths_to_prev]\n",
    "        \n",
    "        # it's possible we already know a shortest path to here as well\n",
    "        old_paths_to_here = shortest_paths_to.get(user_id, [])\n",
    "        \n",
    "        # what's the shortest path to here that we've seen so far?\n",
    "        if old_paths_to_here:\n",
    "            min_path_length = len(old_paths_to_here[0])\n",
    "        else:\n",
    "            min_path_length = float('inf')\n",
    "                \n",
    "        # any new paths to here that aren't too long\n",
    "        new_paths_to_here = [path_via_prev\n",
    "                             for path_via_prev in paths_via_prev\n",
    "                             if len(path_via_prev) <= min_path_length\n",
    "                             and path_via_prev not in old_paths_to_here]\n",
    "        \n",
    "        shortest_paths_to[user_id] = old_paths_to_here + new_paths_to_here\n",
    "        \n",
    "        # add new neighbors to the frontier\n",
    "        frontier.extend((user, friend)\n",
    "                        for friend in user[\"friends\"]\n",
    "                        if friend[\"id\"] not in shortest_paths_to)\n",
    "\n",
    "    return shortest_paths_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can store these `dicts` with each node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    user[\"shortest_paths\"] = shortest_paths_from(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're finally ready to calculate betweenness centrality.  \n",
    "For every pair of nodes $i$ and $j$, we know the $n$ shortest paths from $i$ to $j$.  \n",
    "Then, for each of those paths, we just add $1/n$ to the centrality of each node on that path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 3.5\n",
      "2 3.5\n",
      "3 18.0\n",
      "4 20.0\n",
      "5 20.5\n",
      "6 6.0\n",
      "7 6.0\n",
      "8 8.5\n",
      "9 0.0\n"
     ]
    }
   ],
   "source": [
    "for user in users:\n",
    "    user[\"betweenness_centrality\"] = 0.0\n",
    "    \n",
    "for source in users:\n",
    "    source_id = source[\"id\"]\n",
    "    for target_id, paths in source[\"shortest_paths\"].iteritems():\n",
    "        if source_id < target_id:    # don't double count\n",
    "            num_paths = len(paths)   # how many shortest_paths?\n",
    "            contrib = 1 / num_paths  # contribution to centrality\n",
    "            for path in paths:\n",
    "                for id in path:\n",
    "                    if id not in [source_id, target_id]:\n",
    "                        users[id][\"betweenness_centrality\"] += contrib\n",
    "\n",
    "for user in users:\n",
    "    print user[\"id\"], user[\"betweenness_centrality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author included a nice visualization to show the relationships:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![betweenness_centrality](img/betweenness_centrality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, users 0 and 9 have centrality 0.0 (meaning that neither one is on any shortest path between other users), whereas users 3, 4, and 5 all have high centralities (meaning that all three lie on many shortest paths).  \n",
    "Generally the centrality numbers are relative and aren't that meaningful themselves; what we care about is how the numbers for each node compare to the numbers for other nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closeness Centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Another measure that we can look at is [closeness centrality](https://en.wikipedia.org/wiki/Centrality#Closeness_centrality).  \n",
    "First, for each user we calculate her [farness](http://www.analytictech.com/ucinet/help/oeky47.htm), which is the sum of the lengths of her shortest paths to each other user.  \n",
    "Since we've already computed the shortest paths between each pair of nodes, we can add up their lengths.  \n",
    "If there are multiple shortest paths, they all have the same length, so we can just look at the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def farness(user):\n",
    "    \"\"\" the sum of the lengths of the shortest paths to each other user \"\"\"\n",
    "    return sum(len(paths[0]) for paths in user[\"shortest_paths\"].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go on and calculate closeness centrality as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0294117647059\n",
      "1 0.037037037037\n",
      "2 0.037037037037\n",
      "3 0.0454545454545\n",
      "4 0.05\n",
      "5 0.05\n",
      "6 0.0416666666667\n",
      "7 0.0416666666667\n",
      "8 0.0357142857143\n",
      "9 0.0277777777778\n"
     ]
    }
   ],
   "source": [
    "for user in users:\n",
    "    user[\"closeness_centrality\"] = 1 / farness(user)\n",
    "    print user[\"id\"], user[\"closeness_centrality\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here's another pretty picture courtesy of the author to complement our results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![closeness_centrality](img/closeness_centrality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is much less variation here -- even the very central nodes are still pretty far from the out on the periphery.  \n",
    "Calculating shortest paths can be a bit of a challenge, which is one reason why betweenness and closeness centrality aren't often used on large networks.  \n",
    "The less intuitive (but generally easier to compute) [eigenvector centrality](https://en.wikipedia.org/wiki/Eigenvector_centrality) is more frequently used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
