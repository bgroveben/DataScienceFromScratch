{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **If you choose to run this entire file, it will take ~20-25 minutes to complete due to the data being scraped.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9. Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter\n",
    "import math, random, csv, json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be a data scientist you need data (yes, really).  \n",
    "In this chapter, we take a look at different ways of getting data into Python and into the right formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stdin and stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run your Python scripts at the command line, you can *pipe* data through them using <code>sys.stdin</code> and <code>sys.stdout</code>.  \n",
    "For example, here is a script that reads in lines of text and spits back out the ones that match a regular expression:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# egrep.py\n",
    "import sys, re\n",
    "\n",
    "# sys.argv is the list of command-line arguments\n",
    "# sys.argv[0] is the name of the program itself\n",
    "# sys.argv[1] will be the regex specified at the command line\n",
    "regex = sys.argv[1]\n",
    "\n",
    "# for every line passed into the script\n",
    "for line in sys.stdin:\n",
    "    # if it matches the regex, write it to stdout\n",
    "    if re.search(regex, line):\n",
    "        sys.stdout.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a program that counts the lines it receives and then writes out the count:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# line_count.py\n",
    "import sys\n",
    "\n",
    "count = 0\n",
    "for line in sys.stdin:\n",
    "    count += 1\n",
    "    \n",
    "# print goes to sys.stdout\n",
    "print count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could then use these to count how many lines of a file contain numbers.  \n",
    "In Windows, you would use:  \n",
    "\n",
    "<code>type SomeFile.txt | python egrep.py \"[0-9]\" | python line_count.py</code>  \n",
    "\n",
    "whereas in a Unix system you would use:  \n",
    "\n",
    "<code>cat SomeFile.txt | python egrep.py \"[0-9]\" | python line_count.py</code>  \n",
    "\n",
    "The | is the pipe character, which means \"use the output of the left command as the input of the right command\".  \n",
    "You can build some pretty elaborate data-processing pipelines this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, here is a script that counts the words in its input and writes out the most common ones:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# most_common_words.py  \n",
    "\n",
    "import sys \n",
    "from collections import Counter  \n",
    "\n",
    "# pass in number of words as the first argument\n",
    "\n",
    "try:\n",
    "    num_words = int(sys.argv[1])   \n",
    "except:\n",
    "    print \"usage: most_common_words.py num_words\"\n",
    "    sys.exit(1)   # non-zero exit code indicates error\n",
    "\n",
    "counter = Counter(word.lower()                      # lowercase words                  \n",
    "                  for line in sys.stdin   \n",
    "                  for word in line.strip().split()  #  split on spaces  \n",
    "                  if word)                          # skip empty 'words' (spaces)  \n",
    "                  \n",
    "for word, count in counter.most_common(num_words):\n",
    "    sys.stdout.write(str(count))\n",
    "    sys.stdout.write(\"\\t\")\n",
    "    sys.stdout.write(word)\n",
    "    sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\teget\r\n",
      "7\tin\r\n",
      "6\tnon\r\n",
      "5\tsed\r\n",
      "5\tut\r\n",
      "4\tvel\r\n",
      "4\tet\r\n",
      "4\tnulla\r\n",
      "4\tneque\r\n",
      "4\tullamcorper\r\n"
     ]
    }
   ],
   "source": [
    "cat lorem_ipsum.txt | python most_common_words.py 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**  \n",
    "There are plenty of Unix command-line tools that can also be used, such as <code>grep</code> and <code>egrep</code>, that are probably preferable to building your own from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Basics of Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in working with a text file is to obtain a *file object* using `open`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'r' means read-only\n",
    "file_for_reading = open('reading_file.txt', 'r')\n",
    "\n",
    "# 'w' means write\n",
    "#!# This will destroy the file if it already exists!\n",
    "file_for_writing = open('writing_file.txt', 'w')\n",
    "\n",
    "# 'a' means append\n",
    "# for adding to the end of a file\n",
    "file_for_appending = open('appending_file.txt', 'a')\n",
    "\n",
    "#!# Don't forget to close your files when you're done!\n",
    "file_for_reading.close()\n",
    "file_for_writing.close()\n",
    "file_for_appending.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is easy to forget to close your files, you should always use them in a `with` block, at the end of which they will be closed automatically:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('reading_file.txt', 'r') as f:\n",
    "    data = function_that_gets_data_from(f)\n",
    "    \n",
    "# at this point f has already been closed, so don't try to use it\n",
    "\n",
    "process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to read a whole text file, you can just iterate over the lines of the file using `for`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starts_with_hash = 0\n",
    "\n",
    "with open('lorem_ipsum.txt', 'r') as f:\n",
    "    for line in f:                 # look at each line in the file\n",
    "        if re.match(\"^#\",line):    # use a regex to see if it starts with '#'\n",
    "            starts_with_hash += 1  # if it does, add 1 to the count\n",
    "\n",
    "starts_with_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every line you get this way ends in a newline character (\\n), you you may want to `strip()` it before doing anything with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, imagine you have a file full of email addresses, one per line, and that you need to generate a histogram of the domains.  \n",
    "A good first approximation is to just take the parts of the email addresses that come after the @."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_domain(email_address):\n",
    "    \"\"\" split on '@' and return the last piece \"\"\"\n",
    "    return email_address.lower().split(\"@\")[-1]\n",
    "\n",
    "with open('email_addresses.txt', 'r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip()) for line in f if \"@\" in line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delimited Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently you will work with files that have lots of data on each line.  \n",
    "These files are often either *comma-separated* or *tab-separated*.  \n",
    "Don't try to parse them yourself -- use Python's `csv` module or the `pandas` library.  \n",
    "If the file has no headers, you can use `csv.reader` to iterate over the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we had a tab-delimited file of stock prices, we could process them with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('6/20/2014', 'AAPL', 90.91)\n",
      "('6/20/2014', 'MSFT', 41.68)\n",
      "('6/20/2014', 'FB', 64.5)\n",
      "('6/19/2014', 'AAPL', 91.86)\n",
      "('6/19/2014', 'MSFT', 41.51)\n",
      "('6/19/2014', 'FB', 64.34)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('tab_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        print(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your file has headers, you can either skip the header row (with an initial call to `reader.next()`), or get each row as a `dict`, with the headers as keys, by using `csv.DictReader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('6/20/2014', 'AAPL', 90.91)\n",
      "('6/20/2014', 'MSFT', 41.68)\n",
      "('6/20/2014', 'FB', 64.5)\n"
     ]
    }
   ],
   "source": [
    "with open('colon_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=':')\n",
    "    for row in reader:\n",
    "        date = row[\"date\"]\n",
    "        symbol = row[\"symbol\"]\n",
    "        closing_price = float(row[\"closing_price\"])\n",
    "        print(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if your file doesn't have headers you can still use `DictReader` by passing it the keys as a `fieldnames` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can similarly write out delimited data using `csv.writer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "today_prices = { 'AAPL' : 95.95, 'MSFT' : 43.34, 'FB' : 66.66 }\n",
    "\n",
    "with open('comma_delimited_stock_prices.txt', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for stock, price in today_prices.items():\n",
    "        writer.writerow([stock, price])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`csv.writer()` will do the right thing if your fields themselves have commas in them.  \n",
    "Your own hand-rolled writer probably won't.  \n",
    "For example, if you attempt: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = [[\"test1\", \"success\", \"Monday\"],\n",
    "           [\"test2\", \"success, kind of\", \"Tuesday\"],\n",
    "           [\"test3\", \"failure, kind of\", \"Wednesday\"],\n",
    "           [\"test4\", \"failure, utter\", \"Thursday\"]]\n",
    "\n",
    "#!# don't do this!\n",
    "with open('bad_csv.csv', 'w') as f:\n",
    "    for row in results:\n",
    "        f.write(\",\".join(map(str, row)))  # might have too many commas in it\n",
    "        f.write(\"\\n\")                     # row might have newlines as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will end up with a `csv` file that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test1', 'success', 'Monday']\n",
      "['test2', 'success', ' kind of', 'Tuesday']\n",
      "['test3', 'failure', ' kind of', 'Wednesday']\n",
      "['test4', 'failure', ' utter', 'Thursday']\n"
     ]
    }
   ],
   "source": [
    "with open('bad_csv.csv', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that will be very difficult to make sense of.  \n",
    "Open the `bad_csv.csv` file in a text editor and see for yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the Web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### HTML and the Parsing Thereof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get data out of HTML, we will use the [BeautifulSoup library](https://www.crummy.com/software/BeautifulSoup/), which builds a tree out of the various elements on a web page and provides a simple interface for accessing them.  \n",
    "We will also be using the [requests library](http://docs.python-requests.org/en/latest/), which is a much nicer way of making HTTP requests than anything that's built into Python.  \n",
    "Python's built-in HTML parser is not very lenient, meaning that it doesn't deal well with HTML that's not perfectly formed, so we will use [html5lib](https://github.com/html5lib/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Beautiful Soup, we need to pass some HTML into the `BeautifulSoup()` function.  \n",
    "In our examples, this will be the result of a call to `requests.get`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "html = requests.get(\"http://www.example.com\").text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after which we can get pretty far using a few simple methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will typically work with `Tag` objects, which correspond to the tags representing the structure of an HTML page.  \n",
    "For example, to find the first `<p>` tag (and its contents), you can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is established to be used for illustrative examples in documents. You may use this\\n    domain in examples without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph = soup.find('p')  # or just soup.p -- see below\n",
    "first_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>This domain is established to be used for illustrative examples in documents. You may use this\\n    domain in examples without prior coordination or asking for permission.</p>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "also_first_paragraph = soup.p\n",
    "also_first_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the text contents of a `Tag` using its `text` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'This domain is established to be used for illustrative examples in documents. You may use this\\n    domain in examples without prior coordination or asking for permission.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'This',\n",
       " u'domain',\n",
       " u'is',\n",
       " u'established',\n",
       " u'to',\n",
       " u'be',\n",
       " u'used',\n",
       " u'for',\n",
       " u'illustrative',\n",
       " u'examples',\n",
       " u'in',\n",
       " u'documents.',\n",
       " u'You',\n",
       " u'may',\n",
       " u'use',\n",
       " u'this',\n",
       " u'domain',\n",
       " u'in',\n",
       " u'examples',\n",
       " u'without',\n",
       " u'prior',\n",
       " u'coordination',\n",
       " u'or',\n",
       " u'asking',\n",
       " u'for',\n",
       " u'permission.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph_words = soup.p.text.split()\n",
    "first_paragraph_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can extract a tag's attributes by treating it like a `dict`:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "first_paragraph_id = soup.p['id']  # raises KeyError if no 'id'\n",
    "first_paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "first_paragraph_id2 = soup.p.get('id')  # returns None if no 'id'\n",
    "print(first_paragraph_id2)\n",
    "first_paragraph_id2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get multiple tags at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is established to be used for illustrative examples in documents. You may use this\\n    domain in examples without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"http://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paragraphs = soup.find_all('p')  # or just soup('p')\n",
    "all_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>This domain is established to be used for illustrative examples in documents. You may use this\\n    domain in examples without prior coordination or asking for permission.</p>,\n",
       " <p><a href=\"http://www.iana.org/domains/example\">More information...</a></p>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "also_all_paragraphs = soup('p')\n",
    "also_all_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_with_ids = [p for p in soup('p') if p.get('id')]\n",
    "paragraphs_with_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently you will want to find tags with a specific `class`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_paragraphs = soup('p', {'class' : 'important'})\n",
    "important_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_paragraphs2 = soup('p', 'important')\n",
    "important_paragraphs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_paragraphs3 = [p for p in soup('p') if 'important' in p.get('class', [])]\n",
    "important_paragraphs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine methods to implement more elaborate logic.  \n",
    "For example, if you want to find every `<span>` element that is contained in a `<div>` element, you could do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning -- this will return the same span multiple times if it lies within multiple divs\n",
    "# If that is the case, be more clever\n",
    "span_inside_divs = [span \n",
    "                    for div in soup('div')    # for each <div> on the page, \n",
    "                    for span in div('span')]  # find each <span> inside of it.\n",
    "span_inside_divs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Enough with the basics, let's look at an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: O'Reilly Books About Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A potential investor in DataSciencester thinks data is just a fad.  \n",
    "To prove him wrong, you decide to examine how many data books O'Reilly has published over time.  \n",
    "Whenever you want to scrape data, check to see if there is some sort of access policy like the one at `http://oreilly.com/terms/`.  \n",
    "In order to be good citizens, we should also check for a `robots.txt` file that tells webcrawlers how to behave, which we can find at `http://shop.oreilly.com/robots.txt`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "User-agent: * \n",
    "Crawl-delay: 30 \n",
    "Request-rate: 1/30 \n",
    "Disallow: /util/ \n",
    "Disallow: /account \n",
    "Disallow: /text/products/\n",
    "Disallow: /category/deals/\n",
    "Disallow: /*QuickView.do\n",
    "Disallow: /*ReviewSubmit.do*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`Crawl-delay: 30` tells us that we should wait 30 seconds between requests.  \n",
    "`Request-rate: 1/30` tells us that we should only request one page every 30 seconds.  \n",
    "The `Disallow` notifications tell us which directories *not* to scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To figure out how to extract the data, let's download one of those pages and feed it to BeautifulSoup:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "url = \"http://shop.oreilly.com/category/browse-subjects/data.do?sortby=publicationDate&page=1\"\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "# Print first 20 lines parsed by BeautifulSoup, just to make sure I'm getting the correct info.\n",
    "# The output is the same stuff you will see when you open the browser's developer tools and view the HTML elements.\n",
    "result = soup.prettify().splitlines()\n",
    "print(result[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you view the page source in your developer's tools, you will see that each book or video seems to be uniquely contained in a `<td>` table cell element with a `class` of `thumbtext` (`td.thumbtext`)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Each book/video title on the page has a CSS class of 'thumbheader'\n",
    "titles = soup.select(\".thumbheader\")\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good first step is to find all of the `td thumbtext` tag elements:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tds = soup('td', 'thumbtext')\n",
    "print len(tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we filter out the videos because the would-be investor is only impressed by books.  \n",
    "If we inspect the HTML further, we can see that each `td` contains one or more `span` elements whose `class` is `pricelabel` and whose text looks like `Ebook:`, `Video:`, or `Print:`.  \n",
    "It appears that the videos contain only one `pricelabel`, whose `text` begins with `Video` (after removing leading spaces).  \n",
    "This means we can test for videos with:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def is_video(td):\n",
    "    \"\"\" it's a video if it has exactly one pricelabel and \n",
    "        if the stripped text inside that pricelabel begins with 'Video\"\"\"\n",
    "    pricelabels = td('span', 'pricelabel')\n",
    "    return (len(pricelabels) == 1 and pricelabels[0].text.strip().startswith(\"Video\"))\n",
    "\n",
    "print len([td for td in tds if not is_video(td)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to start pulling data out of the `td` elements.  \n",
    "It looks like the book title is the text inside the `<a>` tag inside the `<div class=\"thumbheader\">`:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "title = td.find(\"div\", \"thumbheader\").a.text\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The author(s) are in the text of the `AuthorName <div>`.  \n",
    "They are prefaced by the word `By` (which we want to remove) and separated by commas (which we want to split out, after which we'll need to get rid of the spaces):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "author_name = td.find('div', 'AuthorName').text\n",
    "authors = [x.strip() for x in re.sub(\"^By \", \"\", author_name).split(\",\")]\n",
    "authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ISBN seems to be contained in the link that's in the `thumbheader <div>`: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "isbn_link = td.find(\"div\", \"thumbheader\").a.get(\"href\")\n",
    "# re.match captures the part of the regex in parentheses\n",
    "isbn = re.match(\"/product/(.*)\\.do\", isbn_link).group(1)\n",
    "isbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the date is just the contents of the `<span class=\"directorydate\">`:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "date = td.find(\"span\", \"directorydate\").text.strip()\n",
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's put all of the above together into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def book_info(td):\n",
    "    \"\"\" given a BeautifulSoup <td> tag representing a book,\n",
    "        extract the book's details and return a dict\"\"\"\n",
    "    title = td.find(\"div\", \"thumbheader\").a.text\n",
    "    by_author = td.find('div', 'AuthorName').text\n",
    "    authors = [x.strip() for x in re.sub(\"^By \", \"\", by_author).split(\",\")]\n",
    "    isbn_link = td.find(\"div\", \"thumbheader\").a.get(\"href\")\n",
    "    isbn = re.match(\"/product/(.*)\\.do\", isbn_link).groups()[0]\n",
    "    date = td.find(\"span\", \"directorydate\").text.strip()\n",
    "    return {\n",
    "        \"title\" : title,\n",
    "        \"authors\" : authors,\n",
    "        \"isbn\" : isbn,\n",
    "        \"date\" : date\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include the `is_video` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_video(td):\n",
    "    \"\"\" it's a video if it has exactly one pricelabel and \n",
    "        if the stripped text inside that pricelabel begins with 'Video\"\"\"\n",
    "    pricelabels = td('span', 'pricelabel')\n",
    "    return (len(pricelabels) == 1 and pricelabels[0].text.strip().startswith(\"Video\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we're ready to scrape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Souping page 1 , 0 found so far.\n",
      "Souping page 2 , 21 found so far.\n",
      "Souping page 3 , 46 found so far.\n",
      "Souping page 4 , 73 found so far.\n",
      "Souping page 5 , 96 found so far.\n",
      "Souping page 6 , 117 found so far.\n",
      "Souping page 7 , 139 found so far.\n",
      "Souping page 8 , 164 found so far.\n",
      "Souping page 9 , 189 found so far.\n",
      "Souping page 10 , 211 found so far.\n",
      "Souping page 11 , 237 found so far.\n",
      "Souping page 12 , 258 found so far.\n",
      "Souping page 13 , 279 found so far.\n",
      "Souping page 14 , 306 found so far.\n",
      "Souping page 15 , 332 found so far.\n",
      "Souping page 16 , 358 found so far.\n",
      "Souping page 17 , 381 found so far.\n",
      "Souping page 18 , 406 found so far.\n",
      "Souping page 19 , 429 found so far.\n",
      "Souping page 20 , 451 found so far.\n",
      "Souping page 21 , 479 found so far.\n",
      "Souping page 22 , 505 found so far.\n",
      "Souping page 23 , 531 found so far.\n",
      "Souping page 24 , 557 found so far.\n",
      "Souping page 25 , 586 found so far.\n",
      "Souping page 26 , 614 found so far.\n",
      "Souping page 27 , 642 found so far.\n",
      "Souping page 28 , 667 found so far.\n",
      "Souping page 29 , 696 found so far.\n",
      "Souping page 30 , 725 found so far.\n",
      "Souping page 31 , 753 found so far.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from time import sleep  # to accommodate the 30 second pause between requests in the robots.txt file\n",
    "\n",
    "base_url = \"http://shop.oreilly.com/category/browse-subjects/data.do?sortby=publicationDate&page=\"\n",
    "books = []\n",
    "NUM_PAGES = 31  # at the time the book was written, probably more by now\n",
    "\n",
    "for page_num in range(1, NUM_PAGES + 1):\n",
    "    print \"Souping page\", page_num, \",\", len(books), \"found so far.\"\n",
    "    url = base_url + str(page_num)\n",
    "    soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "    for td in soup('td', 'thumbtext'):\n",
    "        if not is_video(td):\n",
    "            books.append(book_info(td))\n",
    "    # now be a good citizen and respect the robots.txt\n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**  \n",
    "Extracting data from HTML like this is more data art than data science.  \n",
    "There are many other find-the-books and find-the-titles recipes that would have worked just as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have collected the data, we can plot the numbers of books published each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_year(book):\n",
    "    \"\"\" book[\"date] takes the format 'November 2014', so we need to split on the space and take the second piece \"\"\"\n",
    "    return int(book[\"date\"].split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzXO3jRiWBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115528490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year_counts = Counter(get_year(book) for book in books\n",
    "                      if get_year(book) <= 2016)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "years = sorted(year_counts)\n",
    "book_counts = [year_counts[year] for year in years]\n",
    "# https://docs.python.org/2/library/functions.html#enumerate\n",
    "# plt.plot(years, book_counts) puts all data on the extreme right of the plot and \n",
    "# all years at the bottom of the y-axis\n",
    "years_on_x = [i for i, _ in enumerate(years)]\n",
    "plt.plot(years_on_x, book_counts)\n",
    "# this next line is needed to display the years on the x-axis\n",
    "plt.xticks([i for i, _ in enumerate(years)], years)\n",
    "plt.xlabel(\"Years\")\n",
    "plt.ylabel(\"Number of data books\")\n",
    "plt.title(\"Data is Big!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Many websites and web services provide application programming interfaces (APIs) that allow the user to explicitly request data in a structured format.  \n",
    "This saves the user (you) the trouble of having to scrape them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON and XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "HTTP is a protocol for transferring text, so the data you request through a web API needs to be [serialized](https://en.wikipedia.org/wiki/Serialization) into a string format.  \n",
    "Often this serialization uses JavaScript Object Notation (JSON):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'Joel Grus',\n",
       " 'publicationYear': 2014,\n",
       " 'title': 'Data Science Book',\n",
       " 'topics': ['data', 'science', 'data science']}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ \"title\" : \"Data Science Book\",\n",
    "  \"author\" : \"Joel Grus\",\n",
    "  \"publicationYear\" : 2014,\n",
    "  \"topics\" : [ \"data\", \"science\", \"data science\"] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parse JSON using Python's `json` module.  \n",
    "In particular, we will use its `loads` function, which deserializes a string representing a JSON object into a Python object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'publicationYear': 2014, u'author': u'Joel Grus', u'topics': [u'data', u'science', u'data science'], u'title': u'Data Science Book'}\n"
     ]
    }
   ],
   "source": [
    "import json  \n",
    "\n",
    "# enclose the JSON in triple quotes or you will get a TypeError: expected string or buffer\n",
    "serialized = \"\"\"{ \"title\" : \"Data Science Book\",\n",
    "                  \"author\" : \"Joel Grus\",\n",
    "                  \"publicationYear\" : 2014,\n",
    "                  \"topics\" : [ \"data\", \"science\", \"data science\"] }\"\"\"\n",
    "\n",
    "# parse the JSON to create a Python dict\n",
    "deserialized = json.loads(serialized)\n",
    "if \"data science\" in deserialized[\"topics\"]:\n",
    "    print deserialized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes an API provider hates you and only provides responses in XML:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<Book>\n",
    "  <Title>Data Science Book</Title>\n",
    "  <Author>Joel Grus</Author>\n",
    "  <PublicationYear>2014</PublicationYear>\n",
    "  <Topics>\n",
    "    <Topic>data</Topic>\n",
    "    <Topic>science</Topic>\n",
    "    <Topic>data science</Topic>\n",
    "  </Topics>\n",
    "</Book>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `BeautifulSoup` to get data from XML in much the same way as we used it to get data from HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Unauthenticated API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most APIS these days require you to first authenticate yourself before using them.  \n",
    "Let's take a look at [GitHub's API](https://developer.github.com/v3/), which allows you to do a few simple things without authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'archive_url': u'https://api.github.com/repos/bgroveben/angularOverview/{archive_format}{/ref}',\n",
       " u'assignees_url': u'https://api.github.com/repos/bgroveben/angularOverview/assignees{/user}',\n",
       " u'blobs_url': u'https://api.github.com/repos/bgroveben/angularOverview/git/blobs{/sha}',\n",
       " u'branches_url': u'https://api.github.com/repos/bgroveben/angularOverview/branches{/branch}',\n",
       " u'clone_url': u'https://github.com/bgroveben/angularOverview.git',\n",
       " u'collaborators_url': u'https://api.github.com/repos/bgroveben/angularOverview/collaborators{/collaborator}',\n",
       " u'comments_url': u'https://api.github.com/repos/bgroveben/angularOverview/comments{/number}',\n",
       " u'commits_url': u'https://api.github.com/repos/bgroveben/angularOverview/commits{/sha}',\n",
       " u'compare_url': u'https://api.github.com/repos/bgroveben/angularOverview/compare/{base}...{head}',\n",
       " u'contents_url': u'https://api.github.com/repos/bgroveben/angularOverview/contents/{+path}',\n",
       " u'contributors_url': u'https://api.github.com/repos/bgroveben/angularOverview/contributors',\n",
       " u'created_at': u'2015-08-27T12:14:36Z',\n",
       " u'default_branch': u'master',\n",
       " u'deployments_url': u'https://api.github.com/repos/bgroveben/angularOverview/deployments',\n",
       " u'description': u'AngularJS Conceptual Overview',\n",
       " u'downloads_url': u'https://api.github.com/repos/bgroveben/angularOverview/downloads',\n",
       " u'events_url': u'https://api.github.com/repos/bgroveben/angularOverview/events',\n",
       " u'fork': False,\n",
       " u'forks': 0,\n",
       " u'forks_count': 0,\n",
       " u'forks_url': u'https://api.github.com/repos/bgroveben/angularOverview/forks',\n",
       " u'full_name': u'bgroveben/angularOverview',\n",
       " u'git_commits_url': u'https://api.github.com/repos/bgroveben/angularOverview/git/commits{/sha}',\n",
       " u'git_refs_url': u'https://api.github.com/repos/bgroveben/angularOverview/git/refs{/sha}',\n",
       " u'git_tags_url': u'https://api.github.com/repos/bgroveben/angularOverview/git/tags{/sha}',\n",
       " u'git_url': u'git://github.com/bgroveben/angularOverview.git',\n",
       " u'has_downloads': True,\n",
       " u'has_issues': True,\n",
       " u'has_pages': False,\n",
       " u'has_wiki': True,\n",
       " u'homepage': None,\n",
       " u'hooks_url': u'https://api.github.com/repos/bgroveben/angularOverview/hooks',\n",
       " u'html_url': u'https://github.com/bgroveben/angularOverview',\n",
       " u'id': 41484654,\n",
       " u'issue_comment_url': u'https://api.github.com/repos/bgroveben/angularOverview/issues/comments{/number}',\n",
       " u'issue_events_url': u'https://api.github.com/repos/bgroveben/angularOverview/issues/events{/number}',\n",
       " u'issues_url': u'https://api.github.com/repos/bgroveben/angularOverview/issues{/number}',\n",
       " u'keys_url': u'https://api.github.com/repos/bgroveben/angularOverview/keys{/key_id}',\n",
       " u'labels_url': u'https://api.github.com/repos/bgroveben/angularOverview/labels{/name}',\n",
       " u'language': u'JavaScript',\n",
       " u'languages_url': u'https://api.github.com/repos/bgroveben/angularOverview/languages',\n",
       " u'merges_url': u'https://api.github.com/repos/bgroveben/angularOverview/merges',\n",
       " u'milestones_url': u'https://api.github.com/repos/bgroveben/angularOverview/milestones{/number}',\n",
       " u'mirror_url': None,\n",
       " u'name': u'angularOverview',\n",
       " u'notifications_url': u'https://api.github.com/repos/bgroveben/angularOverview/notifications{?since,all,participating}',\n",
       " u'open_issues': 0,\n",
       " u'open_issues_count': 0,\n",
       " u'owner': {u'avatar_url': u'https://avatars.githubusercontent.com/u/2719094?v=3',\n",
       "  u'events_url': u'https://api.github.com/users/bgroveben/events{/privacy}',\n",
       "  u'followers_url': u'https://api.github.com/users/bgroveben/followers',\n",
       "  u'following_url': u'https://api.github.com/users/bgroveben/following{/other_user}',\n",
       "  u'gists_url': u'https://api.github.com/users/bgroveben/gists{/gist_id}',\n",
       "  u'gravatar_id': u'',\n",
       "  u'html_url': u'https://github.com/bgroveben',\n",
       "  u'id': 2719094,\n",
       "  u'login': u'bgroveben',\n",
       "  u'organizations_url': u'https://api.github.com/users/bgroveben/orgs',\n",
       "  u'received_events_url': u'https://api.github.com/users/bgroveben/received_events',\n",
       "  u'repos_url': u'https://api.github.com/users/bgroveben/repos',\n",
       "  u'site_admin': False,\n",
       "  u'starred_url': u'https://api.github.com/users/bgroveben/starred{/owner}{/repo}',\n",
       "  u'subscriptions_url': u'https://api.github.com/users/bgroveben/subscriptions',\n",
       "  u'type': u'User',\n",
       "  u'url': u'https://api.github.com/users/bgroveben'},\n",
       " u'private': False,\n",
       " u'pulls_url': u'https://api.github.com/repos/bgroveben/angularOverview/pulls{/number}',\n",
       " u'pushed_at': u'2015-08-27T12:15:22Z',\n",
       " u'releases_url': u'https://api.github.com/repos/bgroveben/angularOverview/releases{/id}',\n",
       " u'size': 108,\n",
       " u'ssh_url': u'git@github.com:bgroveben/angularOverview.git',\n",
       " u'stargazers_count': 0,\n",
       " u'stargazers_url': u'https://api.github.com/repos/bgroveben/angularOverview/stargazers',\n",
       " u'statuses_url': u'https://api.github.com/repos/bgroveben/angularOverview/statuses/{sha}',\n",
       " u'subscribers_url': u'https://api.github.com/repos/bgroveben/angularOverview/subscribers',\n",
       " u'subscription_url': u'https://api.github.com/repos/bgroveben/angularOverview/subscription',\n",
       " u'svn_url': u'https://github.com/bgroveben/angularOverview',\n",
       " u'tags_url': u'https://api.github.com/repos/bgroveben/angularOverview/tags',\n",
       " u'teams_url': u'https://api.github.com/repos/bgroveben/angularOverview/teams',\n",
       " u'trees_url': u'https://api.github.com/repos/bgroveben/angularOverview/git/trees{/sha}',\n",
       " u'updated_at': u'2015-08-27T12:15:22Z',\n",
       " u'url': u'https://api.github.com/repos/bgroveben/angularOverview',\n",
       " u'watchers': 0,\n",
       " u'watchers_count': 0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "endpoint = \"https://api.github.com/users/bgroveben/repos\"\n",
    "repos = json.loads(requests.get(endpoint).text)\n",
    "repos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point `repos` is a `list` of Python `dicts`, each representing a public repositiory on my GitHub account.  \n",
    "We can use this data to figure out which months and days of the week I'm most likely to create a repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to deal with the the dates in the response, which are Unicode strings:  \n",
    "\n",
    "u'created_at': u'2015-08-27T12:14:36Z'  \n",
    "\n",
    "which can handled by installing `python-dateutil`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from dateutil.parser import parse\n",
    "\n",
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "month_counts = Counter(date.month for date in dates)\n",
    "weekday_counts = Counter(date.weekday() for date in dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2015, 8, 27, 12, 14, 36, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 2, 8, 12, 25, 24, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 9, 10, 23, 57, 9, tzinfo=tzutc()),\n",
       " datetime.datetime(2013, 7, 25, 2, 18, 17, tzinfo=tzutc()),\n",
       " datetime.datetime(2013, 5, 23, 6, 58, 7, tzinfo=tzutc()),\n",
       " datetime.datetime(2013, 5, 21, 7, 16, 11, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 3, 19, 9, 28, 46, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 3, 19, 8, 26, 17, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 1, 15, 11, 19, 17, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 4, 20, 12, 22, 45, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 8, 6, 3, 42, 27, tzinfo=tzutc()),\n",
       " datetime.datetime(2014, 2, 26, 22, 23, 33, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 5, 15, 11, 11, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 31, 8, 35, 53, tzinfo=tzutc()),\n",
       " datetime.datetime(2014, 10, 10, 11, 34, 55, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 10, 19, 22, 15, 46, tzinfo=tzutc()),\n",
       " datetime.datetime(2014, 10, 10, 11, 45, 5, tzinfo=tzutc()),\n",
       " datetime.datetime(2013, 5, 12, 7, 7, 14, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 4, 22, 12, 40, 6, tzinfo=tzutc()),\n",
       " datetime.datetime(2016, 7, 25, 9, 6, 25, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 8, 27, 8, 54, 36, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 11, 17, 1, 32, 23, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 2, 19, 12, 11, 46, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 6, 12, 8, 16, 35, tzinfo=tzutc()),\n",
       " datetime.datetime(2014, 11, 30, 9, 26, 16, tzinfo=tzutc()),\n",
       " datetime.datetime(2013, 5, 11, 8, 41, 52, tzinfo=tzutc()),\n",
       " datetime.datetime(2014, 6, 1, 0, 7, 6, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 9, 14, 9, 6, 11, tzinfo=tzutc()),\n",
       " datetime.datetime(2013, 6, 27, 1, 33, 11, tzinfo=tzutc()),\n",
       " datetime.datetime(2015, 12, 16, 17, 59, 34, tzinfo=tzutc())]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1,\n",
       "         2: 3,\n",
       "         3: 2,\n",
       "         4: 2,\n",
       "         5: 4,\n",
       "         6: 3,\n",
       "         7: 2,\n",
       "         8: 3,\n",
       "         9: 2,\n",
       "         10: 5,\n",
       "         11: 2,\n",
       "         12: 1})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4, 1: 2, 2: 5, 3: 9, 4: 5, 5: 2, 6: 3})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can get the languages of my last five repositories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'archive_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/{archive_format}{/ref}',\n",
       "  u'assignees_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/assignees{/user}',\n",
       "  u'blobs_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/git/blobs{/sha}',\n",
       "  u'branches_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/branches{/branch}',\n",
       "  u'clone_url': u'https://github.com/bgroveben/coursera_python_fundamentals.git',\n",
       "  u'collaborators_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/collaborators{/collaborator}',\n",
       "  u'comments_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/comments{/number}',\n",
       "  u'commits_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/commits{/sha}',\n",
       "  u'compare_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/compare/{base}...{head}',\n",
       "  u'contents_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/contents/{+path}',\n",
       "  u'contributors_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/contributors',\n",
       "  u'created_at': u'2016-10-31T08:35:53Z',\n",
       "  u'default_branch': u'master',\n",
       "  u'deployments_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/deployments',\n",
       "  u'description': u'Introduction to Data Science in Python via Coursera and the University of Michigan',\n",
       "  u'downloads_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/downloads',\n",
       "  u'events_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/events',\n",
       "  u'fork': False,\n",
       "  u'forks': 0,\n",
       "  u'forks_count': 0,\n",
       "  u'forks_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/forks',\n",
       "  u'full_name': u'bgroveben/coursera_python_fundamentals',\n",
       "  u'git_commits_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/git/commits{/sha}',\n",
       "  u'git_refs_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/git/refs{/sha}',\n",
       "  u'git_tags_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/git/tags{/sha}',\n",
       "  u'git_url': u'git://github.com/bgroveben/coursera_python_fundamentals.git',\n",
       "  u'has_downloads': True,\n",
       "  u'has_issues': True,\n",
       "  u'has_pages': False,\n",
       "  u'has_wiki': True,\n",
       "  u'homepage': None,\n",
       "  u'hooks_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/hooks',\n",
       "  u'html_url': u'https://github.com/bgroveben/coursera_python_fundamentals',\n",
       "  u'id': 72417691,\n",
       "  u'issue_comment_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/issues/comments{/number}',\n",
       "  u'issue_events_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/issues/events{/number}',\n",
       "  u'issues_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/issues{/number}',\n",
       "  u'keys_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/keys{/key_id}',\n",
       "  u'labels_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/labels{/name}',\n",
       "  u'language': u'Jupyter Notebook',\n",
       "  u'languages_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/languages',\n",
       "  u'merges_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/merges',\n",
       "  u'milestones_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/milestones{/number}',\n",
       "  u'mirror_url': None,\n",
       "  u'name': u'coursera_python_fundamentals',\n",
       "  u'notifications_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/notifications{?since,all,participating}',\n",
       "  u'open_issues': 0,\n",
       "  u'open_issues_count': 0,\n",
       "  u'owner': {u'avatar_url': u'https://avatars.githubusercontent.com/u/2719094?v=3',\n",
       "   u'events_url': u'https://api.github.com/users/bgroveben/events{/privacy}',\n",
       "   u'followers_url': u'https://api.github.com/users/bgroveben/followers',\n",
       "   u'following_url': u'https://api.github.com/users/bgroveben/following{/other_user}',\n",
       "   u'gists_url': u'https://api.github.com/users/bgroveben/gists{/gist_id}',\n",
       "   u'gravatar_id': u'',\n",
       "   u'html_url': u'https://github.com/bgroveben',\n",
       "   u'id': 2719094,\n",
       "   u'login': u'bgroveben',\n",
       "   u'organizations_url': u'https://api.github.com/users/bgroveben/orgs',\n",
       "   u'received_events_url': u'https://api.github.com/users/bgroveben/received_events',\n",
       "   u'repos_url': u'https://api.github.com/users/bgroveben/repos',\n",
       "   u'site_admin': False,\n",
       "   u'starred_url': u'https://api.github.com/users/bgroveben/starred{/owner}{/repo}',\n",
       "   u'subscriptions_url': u'https://api.github.com/users/bgroveben/subscriptions',\n",
       "   u'type': u'User',\n",
       "   u'url': u'https://api.github.com/users/bgroveben'},\n",
       "  u'private': False,\n",
       "  u'pulls_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/pulls{/number}',\n",
       "  u'pushed_at': u'2016-11-15T10:29:42Z',\n",
       "  u'releases_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/releases{/id}',\n",
       "  u'size': 7605,\n",
       "  u'ssh_url': u'git@github.com:bgroveben/coursera_python_fundamentals.git',\n",
       "  u'stargazers_count': 0,\n",
       "  u'stargazers_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/stargazers',\n",
       "  u'statuses_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/statuses/{sha}',\n",
       "  u'subscribers_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/subscribers',\n",
       "  u'subscription_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/subscription',\n",
       "  u'svn_url': u'https://github.com/bgroveben/coursera_python_fundamentals',\n",
       "  u'tags_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/tags',\n",
       "  u'teams_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/teams',\n",
       "  u'trees_url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals/git/trees{/sha}',\n",
       "  u'updated_at': u'2016-10-31T08:36:49Z',\n",
       "  u'url': u'https://api.github.com/repos/bgroveben/coursera_python_fundamentals',\n",
       "  u'watchers': 0,\n",
       "  u'watchers_count': 0},\n",
       " {u'archive_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/{archive_format}{/ref}',\n",
       "  u'assignees_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/assignees{/user}',\n",
       "  u'blobs_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/git/blobs{/sha}',\n",
       "  u'branches_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/branches{/branch}',\n",
       "  u'clone_url': u'https://github.com/bgroveben/DataScienceFromScratch.git',\n",
       "  u'collaborators_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/collaborators{/collaborator}',\n",
       "  u'comments_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/comments{/number}',\n",
       "  u'commits_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/commits{/sha}',\n",
       "  u'compare_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/compare/{base}...{head}',\n",
       "  u'contents_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/contents/{+path}',\n",
       "  u'contributors_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/contributors',\n",
       "  u'created_at': u'2016-10-19T22:15:46Z',\n",
       "  u'default_branch': u'master',\n",
       "  u'deployments_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/deployments',\n",
       "  u'description': u'Working my way through the book by Joel Grus.',\n",
       "  u'downloads_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/downloads',\n",
       "  u'events_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/events',\n",
       "  u'fork': False,\n",
       "  u'forks': 0,\n",
       "  u'forks_count': 0,\n",
       "  u'forks_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/forks',\n",
       "  u'full_name': u'bgroveben/DataScienceFromScratch',\n",
       "  u'git_commits_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/git/commits{/sha}',\n",
       "  u'git_refs_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/git/refs{/sha}',\n",
       "  u'git_tags_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/git/tags{/sha}',\n",
       "  u'git_url': u'git://github.com/bgroveben/DataScienceFromScratch.git',\n",
       "  u'has_downloads': True,\n",
       "  u'has_issues': True,\n",
       "  u'has_pages': False,\n",
       "  u'has_wiki': True,\n",
       "  u'homepage': None,\n",
       "  u'hooks_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/hooks',\n",
       "  u'html_url': u'https://github.com/bgroveben/DataScienceFromScratch',\n",
       "  u'id': 71403812,\n",
       "  u'issue_comment_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/issues/comments{/number}',\n",
       "  u'issue_events_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/issues/events{/number}',\n",
       "  u'issues_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/issues{/number}',\n",
       "  u'keys_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/keys{/key_id}',\n",
       "  u'labels_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/labels{/name}',\n",
       "  u'language': u'Jupyter Notebook',\n",
       "  u'languages_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/languages',\n",
       "  u'merges_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/merges',\n",
       "  u'milestones_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/milestones{/number}',\n",
       "  u'mirror_url': None,\n",
       "  u'name': u'DataScienceFromScratch',\n",
       "  u'notifications_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/notifications{?since,all,participating}',\n",
       "  u'open_issues': 0,\n",
       "  u'open_issues_count': 0,\n",
       "  u'owner': {u'avatar_url': u'https://avatars.githubusercontent.com/u/2719094?v=3',\n",
       "   u'events_url': u'https://api.github.com/users/bgroveben/events{/privacy}',\n",
       "   u'followers_url': u'https://api.github.com/users/bgroveben/followers',\n",
       "   u'following_url': u'https://api.github.com/users/bgroveben/following{/other_user}',\n",
       "   u'gists_url': u'https://api.github.com/users/bgroveben/gists{/gist_id}',\n",
       "   u'gravatar_id': u'',\n",
       "   u'html_url': u'https://github.com/bgroveben',\n",
       "   u'id': 2719094,\n",
       "   u'login': u'bgroveben',\n",
       "   u'organizations_url': u'https://api.github.com/users/bgroveben/orgs',\n",
       "   u'received_events_url': u'https://api.github.com/users/bgroveben/received_events',\n",
       "   u'repos_url': u'https://api.github.com/users/bgroveben/repos',\n",
       "   u'site_admin': False,\n",
       "   u'starred_url': u'https://api.github.com/users/bgroveben/starred{/owner}{/repo}',\n",
       "   u'subscriptions_url': u'https://api.github.com/users/bgroveben/subscriptions',\n",
       "   u'type': u'User',\n",
       "   u'url': u'https://api.github.com/users/bgroveben'},\n",
       "  u'private': False,\n",
       "  u'pulls_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/pulls{/number}',\n",
       "  u'pushed_at': u'2016-12-08T12:16:22Z',\n",
       "  u'releases_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/releases{/id}',\n",
       "  u'size': 783,\n",
       "  u'ssh_url': u'git@github.com:bgroveben/DataScienceFromScratch.git',\n",
       "  u'stargazers_count': 0,\n",
       "  u'stargazers_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/stargazers',\n",
       "  u'statuses_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/statuses/{sha}',\n",
       "  u'subscribers_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/subscribers',\n",
       "  u'subscription_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/subscription',\n",
       "  u'svn_url': u'https://github.com/bgroveben/DataScienceFromScratch',\n",
       "  u'tags_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/tags',\n",
       "  u'teams_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/teams',\n",
       "  u'trees_url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch/git/trees{/sha}',\n",
       "  u'updated_at': u'2016-11-15T19:28:30Z',\n",
       "  u'url': u'https://api.github.com/repos/bgroveben/DataScienceFromScratch',\n",
       "  u'watchers': 0,\n",
       "  u'watchers_count': 0},\n",
       " {u'archive_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/{archive_format}{/ref}',\n",
       "  u'assignees_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/assignees{/user}',\n",
       "  u'blobs_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/git/blobs{/sha}',\n",
       "  u'branches_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/branches{/branch}',\n",
       "  u'clone_url': u'https://github.com/bgroveben/coursera_LTP_TF.git',\n",
       "  u'collaborators_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/collaborators{/collaborator}',\n",
       "  u'comments_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/comments{/number}',\n",
       "  u'commits_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/commits{/sha}',\n",
       "  u'compare_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/compare/{base}...{head}',\n",
       "  u'contents_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/contents/{+path}',\n",
       "  u'contributors_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/contributors',\n",
       "  u'created_at': u'2016-10-05T15:11:11Z',\n",
       "  u'default_branch': u'master',\n",
       "  u'deployments_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/deployments',\n",
       "  u'description': u'Coursera class -- Learn To Program: The Fundamentals -- from the University of Toronto',\n",
       "  u'downloads_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/downloads',\n",
       "  u'events_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/events',\n",
       "  u'fork': False,\n",
       "  u'forks': 0,\n",
       "  u'forks_count': 0,\n",
       "  u'forks_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/forks',\n",
       "  u'full_name': u'bgroveben/coursera_LTP_TF',\n",
       "  u'git_commits_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/git/commits{/sha}',\n",
       "  u'git_refs_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/git/refs{/sha}',\n",
       "  u'git_tags_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/git/tags{/sha}',\n",
       "  u'git_url': u'git://github.com/bgroveben/coursera_LTP_TF.git',\n",
       "  u'has_downloads': True,\n",
       "  u'has_issues': True,\n",
       "  u'has_pages': False,\n",
       "  u'has_wiki': True,\n",
       "  u'homepage': None,\n",
       "  u'hooks_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/hooks',\n",
       "  u'html_url': u'https://github.com/bgroveben/coursera_LTP_TF',\n",
       "  u'id': 70072027,\n",
       "  u'issue_comment_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/issues/comments{/number}',\n",
       "  u'issue_events_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/issues/events{/number}',\n",
       "  u'issues_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/issues{/number}',\n",
       "  u'keys_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/keys{/key_id}',\n",
       "  u'labels_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/labels{/name}',\n",
       "  u'language': u'Python',\n",
       "  u'languages_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/languages',\n",
       "  u'merges_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/merges',\n",
       "  u'milestones_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/milestones{/number}',\n",
       "  u'mirror_url': None,\n",
       "  u'name': u'coursera_LTP_TF',\n",
       "  u'notifications_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/notifications{?since,all,participating}',\n",
       "  u'open_issues': 0,\n",
       "  u'open_issues_count': 0,\n",
       "  u'owner': {u'avatar_url': u'https://avatars.githubusercontent.com/u/2719094?v=3',\n",
       "   u'events_url': u'https://api.github.com/users/bgroveben/events{/privacy}',\n",
       "   u'followers_url': u'https://api.github.com/users/bgroveben/followers',\n",
       "   u'following_url': u'https://api.github.com/users/bgroveben/following{/other_user}',\n",
       "   u'gists_url': u'https://api.github.com/users/bgroveben/gists{/gist_id}',\n",
       "   u'gravatar_id': u'',\n",
       "   u'html_url': u'https://github.com/bgroveben',\n",
       "   u'id': 2719094,\n",
       "   u'login': u'bgroveben',\n",
       "   u'organizations_url': u'https://api.github.com/users/bgroveben/orgs',\n",
       "   u'received_events_url': u'https://api.github.com/users/bgroveben/received_events',\n",
       "   u'repos_url': u'https://api.github.com/users/bgroveben/repos',\n",
       "   u'site_admin': False,\n",
       "   u'starred_url': u'https://api.github.com/users/bgroveben/starred{/owner}{/repo}',\n",
       "   u'subscriptions_url': u'https://api.github.com/users/bgroveben/subscriptions',\n",
       "   u'type': u'User',\n",
       "   u'url': u'https://api.github.com/users/bgroveben'},\n",
       "  u'private': False,\n",
       "  u'pulls_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/pulls{/number}',\n",
       "  u'pushed_at': u'2016-10-18T09:33:54Z',\n",
       "  u'releases_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/releases{/id}',\n",
       "  u'size': 10,\n",
       "  u'ssh_url': u'git@github.com:bgroveben/coursera_LTP_TF.git',\n",
       "  u'stargazers_count': 0,\n",
       "  u'stargazers_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/stargazers',\n",
       "  u'statuses_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/statuses/{sha}',\n",
       "  u'subscribers_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/subscribers',\n",
       "  u'subscription_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/subscription',\n",
       "  u'svn_url': u'https://github.com/bgroveben/coursera_LTP_TF',\n",
       "  u'tags_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/tags',\n",
       "  u'teams_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/teams',\n",
       "  u'trees_url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF/git/trees{/sha}',\n",
       "  u'updated_at': u'2016-10-05T15:12:07Z',\n",
       "  u'url': u'https://api.github.com/repos/bgroveben/coursera_LTP_TF',\n",
       "  u'watchers': 0,\n",
       "  u'watchers_count': 0},\n",
       " {u'archive_url': u'https://api.github.com/repos/bgroveben/django-polls/{archive_format}{/ref}',\n",
       "  u'assignees_url': u'https://api.github.com/repos/bgroveben/django-polls/assignees{/user}',\n",
       "  u'blobs_url': u'https://api.github.com/repos/bgroveben/django-polls/git/blobs{/sha}',\n",
       "  u'branches_url': u'https://api.github.com/repos/bgroveben/django-polls/branches{/branch}',\n",
       "  u'clone_url': u'https://github.com/bgroveben/django-polls.git',\n",
       "  u'collaborators_url': u'https://api.github.com/repos/bgroveben/django-polls/collaborators{/collaborator}',\n",
       "  u'comments_url': u'https://api.github.com/repos/bgroveben/django-polls/comments{/number}',\n",
       "  u'commits_url': u'https://api.github.com/repos/bgroveben/django-polls/commits{/sha}',\n",
       "  u'compare_url': u'https://api.github.com/repos/bgroveben/django-polls/compare/{base}...{head}',\n",
       "  u'contents_url': u'https://api.github.com/repos/bgroveben/django-polls/contents/{+path}',\n",
       "  u'contributors_url': u'https://api.github.com/repos/bgroveben/django-polls/contributors',\n",
       "  u'created_at': u'2016-07-25T09:06:25Z',\n",
       "  u'default_branch': u'master',\n",
       "  u'deployments_url': u'https://api.github.com/repos/bgroveben/django-polls/deployments',\n",
       "  u'description': u'Packaging polling_app',\n",
       "  u'downloads_url': u'https://api.github.com/repos/bgroveben/django-polls/downloads',\n",
       "  u'events_url': u'https://api.github.com/repos/bgroveben/django-polls/events',\n",
       "  u'fork': False,\n",
       "  u'forks': 0,\n",
       "  u'forks_count': 0,\n",
       "  u'forks_url': u'https://api.github.com/repos/bgroveben/django-polls/forks',\n",
       "  u'full_name': u'bgroveben/django-polls',\n",
       "  u'git_commits_url': u'https://api.github.com/repos/bgroveben/django-polls/git/commits{/sha}',\n",
       "  u'git_refs_url': u'https://api.github.com/repos/bgroveben/django-polls/git/refs{/sha}',\n",
       "  u'git_tags_url': u'https://api.github.com/repos/bgroveben/django-polls/git/tags{/sha}',\n",
       "  u'git_url': u'git://github.com/bgroveben/django-polls.git',\n",
       "  u'has_downloads': True,\n",
       "  u'has_issues': True,\n",
       "  u'has_pages': False,\n",
       "  u'has_wiki': True,\n",
       "  u'homepage': None,\n",
       "  u'hooks_url': u'https://api.github.com/repos/bgroveben/django-polls/hooks',\n",
       "  u'html_url': u'https://github.com/bgroveben/django-polls',\n",
       "  u'id': 64120008,\n",
       "  u'issue_comment_url': u'https://api.github.com/repos/bgroveben/django-polls/issues/comments{/number}',\n",
       "  u'issue_events_url': u'https://api.github.com/repos/bgroveben/django-polls/issues/events{/number}',\n",
       "  u'issues_url': u'https://api.github.com/repos/bgroveben/django-polls/issues{/number}',\n",
       "  u'keys_url': u'https://api.github.com/repos/bgroveben/django-polls/keys{/key_id}',\n",
       "  u'labels_url': u'https://api.github.com/repos/bgroveben/django-polls/labels{/name}',\n",
       "  u'language': u'Python',\n",
       "  u'languages_url': u'https://api.github.com/repos/bgroveben/django-polls/languages',\n",
       "  u'merges_url': u'https://api.github.com/repos/bgroveben/django-polls/merges',\n",
       "  u'milestones_url': u'https://api.github.com/repos/bgroveben/django-polls/milestones{/number}',\n",
       "  u'mirror_url': None,\n",
       "  u'name': u'django-polls',\n",
       "  u'notifications_url': u'https://api.github.com/repos/bgroveben/django-polls/notifications{?since,all,participating}',\n",
       "  u'open_issues': 0,\n",
       "  u'open_issues_count': 0,\n",
       "  u'owner': {u'avatar_url': u'https://avatars.githubusercontent.com/u/2719094?v=3',\n",
       "   u'events_url': u'https://api.github.com/users/bgroveben/events{/privacy}',\n",
       "   u'followers_url': u'https://api.github.com/users/bgroveben/followers',\n",
       "   u'following_url': u'https://api.github.com/users/bgroveben/following{/other_user}',\n",
       "   u'gists_url': u'https://api.github.com/users/bgroveben/gists{/gist_id}',\n",
       "   u'gravatar_id': u'',\n",
       "   u'html_url': u'https://github.com/bgroveben',\n",
       "   u'id': 2719094,\n",
       "   u'login': u'bgroveben',\n",
       "   u'organizations_url': u'https://api.github.com/users/bgroveben/orgs',\n",
       "   u'received_events_url': u'https://api.github.com/users/bgroveben/received_events',\n",
       "   u'repos_url': u'https://api.github.com/users/bgroveben/repos',\n",
       "   u'site_admin': False,\n",
       "   u'starred_url': u'https://api.github.com/users/bgroveben/starred{/owner}{/repo}',\n",
       "   u'subscriptions_url': u'https://api.github.com/users/bgroveben/subscriptions',\n",
       "   u'type': u'User',\n",
       "   u'url': u'https://api.github.com/users/bgroveben'},\n",
       "  u'private': False,\n",
       "  u'pulls_url': u'https://api.github.com/repos/bgroveben/django-polls/pulls{/number}',\n",
       "  u'pushed_at': u'2016-07-25T10:17:25Z',\n",
       "  u'releases_url': u'https://api.github.com/repos/bgroveben/django-polls/releases{/id}',\n",
       "  u'size': 352,\n",
       "  u'ssh_url': u'git@github.com:bgroveben/django-polls.git',\n",
       "  u'stargazers_count': 0,\n",
       "  u'stargazers_url': u'https://api.github.com/repos/bgroveben/django-polls/stargazers',\n",
       "  u'statuses_url': u'https://api.github.com/repos/bgroveben/django-polls/statuses/{sha}',\n",
       "  u'subscribers_url': u'https://api.github.com/repos/bgroveben/django-polls/subscribers',\n",
       "  u'subscription_url': u'https://api.github.com/repos/bgroveben/django-polls/subscription',\n",
       "  u'svn_url': u'https://github.com/bgroveben/django-polls',\n",
       "  u'tags_url': u'https://api.github.com/repos/bgroveben/django-polls/tags',\n",
       "  u'teams_url': u'https://api.github.com/repos/bgroveben/django-polls/teams',\n",
       "  u'trees_url': u'https://api.github.com/repos/bgroveben/django-polls/git/trees{/sha}',\n",
       "  u'updated_at': u'2016-07-25T09:21:42Z',\n",
       "  u'url': u'https://api.github.com/repos/bgroveben/django-polls',\n",
       "  u'watchers': 0,\n",
       "  u'watchers_count': 0},\n",
       " {u'archive_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/{archive_format}{/ref}',\n",
       "  u'assignees_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/assignees{/user}',\n",
       "  u'blobs_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/git/blobs{/sha}',\n",
       "  u'branches_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/branches{/branch}',\n",
       "  u'clone_url': u'https://github.com/bgroveben/DEV208xjQuery.git',\n",
       "  u'collaborators_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/collaborators{/collaborator}',\n",
       "  u'comments_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/comments{/number}',\n",
       "  u'commits_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/commits{/sha}',\n",
       "  u'compare_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/compare/{base}...{head}',\n",
       "  u'contents_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/contents/{+path}',\n",
       "  u'contributors_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/contributors',\n",
       "  u'created_at': u'2016-04-22T12:40:06Z',\n",
       "  u'default_branch': u'master',\n",
       "  u'deployments_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/deployments',\n",
       "  u'description': u'Introduction to jQuery courtesy of Microsoft and edX. ',\n",
       "  u'downloads_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/downloads',\n",
       "  u'events_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/events',\n",
       "  u'fork': False,\n",
       "  u'forks': 0,\n",
       "  u'forks_count': 0,\n",
       "  u'forks_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/forks',\n",
       "  u'full_name': u'bgroveben/DEV208xjQuery',\n",
       "  u'git_commits_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/git/commits{/sha}',\n",
       "  u'git_refs_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/git/refs{/sha}',\n",
       "  u'git_tags_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/git/tags{/sha}',\n",
       "  u'git_url': u'git://github.com/bgroveben/DEV208xjQuery.git',\n",
       "  u'has_downloads': True,\n",
       "  u'has_issues': True,\n",
       "  u'has_pages': False,\n",
       "  u'has_wiki': True,\n",
       "  u'homepage': None,\n",
       "  u'hooks_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/hooks',\n",
       "  u'html_url': u'https://github.com/bgroveben/DEV208xjQuery',\n",
       "  u'id': 56854462,\n",
       "  u'issue_comment_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/issues/comments{/number}',\n",
       "  u'issue_events_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/issues/events{/number}',\n",
       "  u'issues_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/issues{/number}',\n",
       "  u'keys_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/keys{/key_id}',\n",
       "  u'labels_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/labels{/name}',\n",
       "  u'language': u'HTML',\n",
       "  u'languages_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/languages',\n",
       "  u'merges_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/merges',\n",
       "  u'milestones_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/milestones{/number}',\n",
       "  u'mirror_url': None,\n",
       "  u'name': u'DEV208xjQuery',\n",
       "  u'notifications_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/notifications{?since,all,participating}',\n",
       "  u'open_issues': 0,\n",
       "  u'open_issues_count': 0,\n",
       "  u'owner': {u'avatar_url': u'https://avatars.githubusercontent.com/u/2719094?v=3',\n",
       "   u'events_url': u'https://api.github.com/users/bgroveben/events{/privacy}',\n",
       "   u'followers_url': u'https://api.github.com/users/bgroveben/followers',\n",
       "   u'following_url': u'https://api.github.com/users/bgroveben/following{/other_user}',\n",
       "   u'gists_url': u'https://api.github.com/users/bgroveben/gists{/gist_id}',\n",
       "   u'gravatar_id': u'',\n",
       "   u'html_url': u'https://github.com/bgroveben',\n",
       "   u'id': 2719094,\n",
       "   u'login': u'bgroveben',\n",
       "   u'organizations_url': u'https://api.github.com/users/bgroveben/orgs',\n",
       "   u'received_events_url': u'https://api.github.com/users/bgroveben/received_events',\n",
       "   u'repos_url': u'https://api.github.com/users/bgroveben/repos',\n",
       "   u'site_admin': False,\n",
       "   u'starred_url': u'https://api.github.com/users/bgroveben/starred{/owner}{/repo}',\n",
       "   u'subscriptions_url': u'https://api.github.com/users/bgroveben/subscriptions',\n",
       "   u'type': u'User',\n",
       "   u'url': u'https://api.github.com/users/bgroveben'},\n",
       "  u'private': False,\n",
       "  u'pulls_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/pulls{/number}',\n",
       "  u'pushed_at': u'2016-05-19T06:43:21Z',\n",
       "  u'releases_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/releases{/id}',\n",
       "  u'size': 92,\n",
       "  u'ssh_url': u'git@github.com:bgroveben/DEV208xjQuery.git',\n",
       "  u'stargazers_count': 0,\n",
       "  u'stargazers_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/stargazers',\n",
       "  u'statuses_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/statuses/{sha}',\n",
       "  u'subscribers_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/subscribers',\n",
       "  u'subscription_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/subscription',\n",
       "  u'svn_url': u'https://github.com/bgroveben/DEV208xjQuery',\n",
       "  u'tags_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/tags',\n",
       "  u'teams_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/teams',\n",
       "  u'trees_url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery/git/trees{/sha}',\n",
       "  u'updated_at': u'2016-04-22T12:47:28Z',\n",
       "  u'url': u'https://api.github.com/repos/bgroveben/DEV208xjQuery',\n",
       "  u'watchers': 0,\n",
       "  u'watchers_count': 0}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_5_repos = sorted(repos, key=lambda r: r[\"created_at\"], reverse=True)[:5]\n",
    "last_5_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Jupyter Notebook', u'Jupyter Notebook', u'Python', u'Python', u'HTML']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_5_languages = [repo[\"language\"] for repo in last_5_repos]\n",
    "last_5_languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is unusual to have to work with APIs at such a low level, like making the requests and parsing the responses ourselves.  \n",
    "Someone else has (probably) already built a Python library for using pretty much any API you are interested in using.  \n",
    "Still, you will occasionally have to roll your own API access library, debug someone else's, or have to figure out how to deal with a poorly written one, so it is good to know the details of how APIs work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you are looking for lists of APIs that have Python wrappers you can use [Python for Beginners](http://www.pythonforbeginners.com/development/list-of-python-apis/).  \n",
    "A directory of web APIs that may or may not have Python wrappers can be found at [The Programmable Web](http://www.programmableweb.com/).\n",
    "You can always resort to a Google search for 'python whatever API' or, as a last resort, you can always scrape your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Using the Twitter APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To interact with Twitter's APIs we'll be using the [Twython](https://github.com/ryanmcgrath/twython) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objetpetitm : @angadc but work even in better in data science. just throw in, casually, deep learning, stochastic model, bayesian inference. like voodoo.\n",
      "\n",
      "HenryAkrofi : RT @KirkDBorne: Become a #DataScientist now.\n",
      "\n",
      "Get a job, or your money back!\n",
      "\n",
      "https://t.co/afNsbBvAn6 by @Springboard\n",
      "\n",
      "#BigData #DataScienc\n",
      "\n",
      "Shiva_jai : RT @AnalyticsVidhya: #DataScience #Medium handles to follow: https://t.co/dik1iwNbDy @ageitgey @mrogati @SamDeBrule @olivercameron @NathanB\n",
      "\n",
      "jsunster : The 'fintech' approach to data science and machine learning https://t.co/uH8opTlJyU https://t.co/VGPMHnzBXx\n",
      "\n",
      "htpotter : RT @HarvardBiz: Businesses are constantly generating enormous amounts of data but it doesnt always translate to actionable info https://t.\n",
      "\n",
      "Worville : RT @pydatasci: The Python Data Science Handbook is now available! The entire book is also openly published as Jupyter notebooks: https://t.\n",
      "\n",
      "DataFest_ : RT @ImDataScientist: RT @edXOnline: The Importance of #DataScience in the 21st Century: https://t.co/tf8cMrMTlb https://t.co/JdghyPEiee\n",
      "\n",
      "MrDark101 : RT @HarvardBiz: Businesses are constantly generating enormous amounts of data but it doesnt always translate to actionable info https://t.\n",
      "\n",
      "TrailheadBoise : RT @HarvardBiz: Businesses are constantly generating enormous amounts of data but it doesnt always translate to actionable info https://t.\n",
      "\n",
      "ChrisSeminoff : bigdata: #StrataHadoop Singapore  stay in touch: Join our Linkedin group: \"Hardcore Data Science &amp; Data Engineer https://t.co/mNmYO82b4R\n",
      "\n",
      "AshaPoulose : RT @TaoriShilpy: Very informative session on Data Science and Machine Learning by @AshaPoulose @suklachandra Day1 #GHCI16 https://t.co/BgGr\n",
      "\n",
      "lunaayalar : RT @jose_garde: Refining Data is Tough. Heres How to Make it Easier - https://t.co/sxxsMMKoK2  - #Marketing\n",
      "\n",
      "EliteHRV : How to increase confidence in your data for decision making. Podcast: https://t.co/l99EiiIHBs\n",
      "\n",
      "WDSI_Warwick : RT @turinginst: We are offering Fellowships to candidates with cross cutting skills &amp; research interests in the area of data science\n",
      "https:\n",
      "\n",
      "newsyc150 : Introduction to K-means Clustering https://t.co/jdWY17z4mI (https://t.co/eVyULCVqo0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from twython import Twython\n",
    "\n",
    "def search_twitter_for_data_science():\n",
    "    \"\"\" search for tweets containing the phrase 'data science' \"\"\"\n",
    "    # put credentials in a separate file outside of version control and access them with json.load()\n",
    "    with open('credentials.json') as json_data:\n",
    "        credentials = json.load(json_data)\n",
    "        consumer_key = credentials[0][\"CONSUMER_KEY\"]\n",
    "        consumer_secret = credentials[0][\"CONSUMER_SECRET\"]\n",
    "    \n",
    "    # use Twython to make API calls\n",
    "    twitter = Twython(consumer_key, consumer_secret)\n",
    "    # search for tweets containing the phrase \"data science\"\n",
    "    for status in twitter.search(q='\"data science\"')[\"statuses\"]:\n",
    "        # tweets often contain Unicode characters that print can't deal with, hence the .encode('utf-8')\n",
    "        user = status[\"user\"][\"screen_name\"].encode('utf-8')\n",
    "        text = status[\"text\"].encode('utf-8')\n",
    "        # user's screen name and their respective tweets (with a line of whitespace between entries for readability)\n",
    "        print user, \":\", text\n",
    "        print\n",
    "        \n",
    "search_twitter_for_data_science()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, but not terribly interesting, largely because the Twitter Search API just shows you whatever handful of recent results if feels like.  \n",
    "When you're doing data science, more often you will want a *lot* of tweets.  \n",
    "This is where the [Streaming API](https://dev.twitter.com/streaming/reference/get/statuses/sample) is useful.  \n",
    "This is how you access a sample of the great Twitter firehose of data.\n",
    "To use it, the user needs to authenticate using their access tokens.  \n",
    "In order to access the Streaming API with Twython, we need to define a class that inherits from `TwythonStreamer` and that overrides its `on_success()` method and possibly its `on_error()` method as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "\n",
    "# appending data to a global variable is poor form, but it makes the example much simpler\n",
    "tweets = []\n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    \"\"\" subclass of TwythonStreamer that specifies how to interact with the stream \"\"\"\n",
    "    \n",
    "    def on_success(self, data):\n",
    "        \"\"\" what to do when twitter sends us data -- a Python dict will represent a tweet \"\"\"\n",
    "        \n",
    "        # only collect tweets that are in English\n",
    "        if data['lang'] == 'en':\n",
    "            tweets.append(data)\n",
    "            print \"received tweet #\", len(tweets)\n",
    "            \n",
    "        # stop when we have collected enough\n",
    "        if len(tweets) >= 1000:\n",
    "            self.disconnect()\n",
    "            \n",
    "    def on_error(self, status_code, data):\n",
    "        print status_code, data\n",
    "        self.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MyStreamer will connect to the Twitter stream and wait for Twitter to feed it data.  \n",
    "Each time it receives some data (here, a Tweet represented as a Python object), it passes that object to the `on_success()` method, which appends it to our `tweets` list (if it is in English), and then disconnects the streamer after 1000 tweets have been collected.  \n",
    "Got it? Good.  \n",
    "Let's initialize this thing and get it running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received tweet # 1\n",
      "received tweet # 2\n",
      "received tweet # 3\n",
      "received tweet # 4\n",
      "received tweet # 5\n",
      "received tweet # 6\n",
      "received tweet # 7\n",
      "received tweet # 8\n",
      "received tweet # 9\n",
      "received tweet # 10\n",
      "received tweet # 11\n",
      "received tweet # 12\n",
      "received tweet # 13\n",
      "received tweet # 14\n",
      "received tweet # 15\n",
      "received tweet # 16\n",
      "received tweet # 17\n",
      "received tweet # 18\n",
      "received tweet # 19\n",
      "received tweet # 20\n",
      "received tweet # 21\n",
      "received tweet # 22\n",
      "received tweet # 23\n",
      "received tweet # 24\n",
      "received tweet # 25\n",
      "received tweet # 26\n",
      "received tweet # 27\n",
      "received tweet # 28\n",
      "received tweet # 29\n",
      "received tweet # 30\n",
      "received tweet # 31\n",
      "received tweet # 32\n",
      "received tweet # 33\n",
      "received tweet # 34\n",
      "received tweet # 35\n",
      "received tweet # 36\n",
      "received tweet # 37\n",
      "received tweet # 38\n",
      "received tweet # 39\n",
      "received tweet # 40\n",
      "received tweet # 41\n",
      "received tweet # 42\n",
      "received tweet # 43\n",
      "received tweet # 44\n",
      "received tweet # 45\n",
      "received tweet # 46\n",
      "received tweet # 47\n",
      "received tweet # 48\n",
      "received tweet # 49\n",
      "received tweet # 50\n",
      "received tweet # 51\n",
      "received tweet # 52\n",
      "received tweet # 53\n",
      "received tweet # 54\n",
      "received tweet # 55\n",
      "received tweet # 56\n",
      "received tweet # 57\n",
      "received tweet # 58\n",
      "received tweet # 59\n",
      "received tweet # 60\n",
      "received tweet # 61\n",
      "received tweet # 62\n",
      "received tweet # 63\n",
      "received tweet # 64\n",
      "received tweet # 65\n",
      "received tweet # 66\n",
      "received tweet # 67\n",
      "received tweet # 68\n",
      "received tweet # 69\n",
      "received tweet # 70\n",
      "received tweet # 71\n",
      "received tweet # 72\n",
      "received tweet # 73\n",
      "received tweet # 74\n",
      "received tweet # 75\n",
      "received tweet # 76\n",
      "received tweet # 77\n",
      "received tweet # 78\n",
      "received tweet # 79\n",
      "received tweet # 80\n",
      "received tweet # 81\n",
      "received tweet # 82\n",
      "received tweet # 83\n",
      "received tweet # 84\n",
      "received tweet # 85\n",
      "received tweet # 86\n",
      "received tweet # 87\n",
      "received tweet # 88\n",
      "received tweet # 89\n",
      "received tweet # 90\n",
      "received tweet # 91\n",
      "received tweet # 92\n",
      "received tweet # 93\n",
      "received tweet # 94\n",
      "received tweet # 95\n",
      "received tweet # 96\n",
      "received tweet # 97\n",
      "received tweet # 98\n",
      "received tweet # 99\n",
      "received tweet # 100\n",
      "received tweet # 101\n",
      "received tweet # 102\n",
      "received tweet # 103\n",
      "received tweet # 104\n",
      "received tweet # 105\n",
      "received tweet # 106\n",
      "received tweet # 107\n",
      "received tweet # 108\n",
      "received tweet # 109\n",
      "received tweet # 110\n",
      "received tweet # 111\n",
      "received tweet # 112\n",
      "received tweet # 113\n",
      "received tweet # 114\n",
      "received tweet # 115\n",
      "received tweet # 116\n",
      "received tweet # 117\n",
      "received tweet # 118\n",
      "received tweet # 119\n",
      "received tweet # 120\n",
      "received tweet # 121\n",
      "received tweet # 122\n",
      "received tweet # 123\n",
      "received tweet # 124\n",
      "received tweet # 125\n",
      "received tweet # 126\n",
      "received tweet # 127\n",
      "received tweet # 128\n",
      "received tweet # 129\n",
      "received tweet # 130\n",
      "received tweet # 131\n",
      "received tweet # 132\n",
      "received tweet # 133\n",
      "received tweet # 134\n",
      "received tweet # 135\n",
      "received tweet # 136\n",
      "received tweet # 137\n",
      "received tweet # 138\n",
      "received tweet # 139\n",
      "received tweet # 140\n",
      "received tweet # 141\n",
      "received tweet # 142\n",
      "received tweet # 143\n",
      "received tweet # 144\n",
      "received tweet # 145\n",
      "received tweet # 146\n",
      "received tweet # 147\n",
      "received tweet # 148\n",
      "received tweet # 149\n",
      "received tweet # 150\n",
      "received tweet # 151\n",
      "received tweet # 152\n",
      "received tweet # 153\n",
      "received tweet # 154\n",
      "received tweet # 155\n",
      "received tweet # 156\n",
      "received tweet # 157\n",
      "received tweet # 158\n",
      "received tweet # 159\n",
      "received tweet # 160\n",
      "received tweet # 161\n",
      "received tweet # 162\n",
      "received tweet # 163\n",
      "received tweet # 164\n",
      "received tweet # 165\n",
      "received tweet # 166\n",
      "received tweet # 167\n",
      "received tweet # 168\n",
      "received tweet # 169\n",
      "received tweet # 170\n",
      "received tweet # 171\n",
      "received tweet # 172\n",
      "received tweet # 173\n",
      "received tweet # 174\n",
      "received tweet # 175\n",
      "received tweet # 176\n",
      "received tweet # 177\n",
      "received tweet # 178\n",
      "received tweet # 179\n",
      "received tweet # 180\n",
      "received tweet # 181\n",
      "received tweet # 182\n",
      "received tweet # 183\n",
      "received tweet # 184\n",
      "received tweet # 185\n",
      "received tweet # 186\n",
      "received tweet # 187\n",
      "received tweet # 188\n",
      "received tweet # 189\n",
      "received tweet # 190\n",
      "received tweet # 191\n",
      "received tweet # 192\n",
      "received tweet # 193\n",
      "received tweet # 194\n",
      "received tweet # 195\n",
      "received tweet # 196\n",
      "received tweet # 197\n",
      "received tweet # 198\n",
      "received tweet # 199\n",
      "received tweet # 200\n",
      "received tweet # 201\n",
      "received tweet # 202\n",
      "received tweet # 203\n",
      "received tweet # 204\n",
      "received tweet # 205\n",
      "received tweet # 206\n",
      "received tweet # 207\n",
      "received tweet # 208\n",
      "received tweet # 209\n",
      "received tweet # 210\n",
      "received tweet # 211\n",
      "received tweet # 212\n",
      "received tweet # 213\n",
      "received tweet # 214\n",
      "received tweet # 215\n",
      "received tweet # 216\n",
      "received tweet # 217\n",
      "received tweet # 218\n",
      "received tweet # 219\n",
      "received tweet # 220\n",
      "received tweet # 221\n",
      "received tweet # 222\n",
      "received tweet # 223\n",
      "received tweet # 224\n",
      "received tweet # 225\n",
      "received tweet # 226\n",
      "received tweet # 227\n",
      "received tweet # 228\n",
      "received tweet # 229\n",
      "received tweet # 230\n",
      "received tweet # 231\n",
      "received tweet # 232\n",
      "received tweet # 233\n",
      "received tweet # 234\n",
      "received tweet # 235\n",
      "received tweet # 236\n",
      "received tweet # 237\n",
      "received tweet # 238\n",
      "received tweet # 239\n",
      "received tweet # 240\n",
      "received tweet # 241\n",
      "received tweet # 242\n",
      "received tweet # 243\n",
      "received tweet # 244\n",
      "received tweet # 245\n",
      "received tweet # 246\n",
      "received tweet # 247\n",
      "received tweet # 248\n",
      "received tweet # 249\n",
      "received tweet # 250\n",
      "received tweet # 251\n",
      "received tweet # 252\n",
      "received tweet # 253\n",
      "received tweet # 254\n",
      "received tweet # 255\n",
      "received tweet # 256\n",
      "received tweet # 257\n",
      "received tweet # 258\n",
      "received tweet # 259\n",
      "received tweet # 260\n",
      "received tweet # 261\n",
      "received tweet # 262\n",
      "received tweet # 263\n",
      "received tweet # 264\n",
      "received tweet # 265\n",
      "received tweet # 266\n",
      "received tweet # 267\n",
      "received tweet # 268\n",
      "received tweet # 269\n",
      "received tweet # 270\n",
      "received tweet # 271\n",
      "received tweet # 272\n",
      "received tweet # 273\n",
      "received tweet # 274\n",
      "received tweet # 275\n",
      "received tweet # 276\n",
      "received tweet # 277\n",
      "received tweet # 278\n",
      "received tweet # 279\n",
      "received tweet # 280\n",
      "received tweet # 281\n",
      "received tweet # 282\n",
      "received tweet # 283\n",
      "received tweet # 284\n",
      "received tweet # 285\n",
      "received tweet # 286\n",
      "received tweet # 287\n",
      "received tweet # 288\n",
      "received tweet # 289\n",
      "received tweet # 290\n",
      "received tweet # 291\n",
      "received tweet # 292\n",
      "received tweet # 293\n",
      "received tweet # 294\n",
      "received tweet # 295\n",
      "received tweet # 296\n",
      "received tweet # 297\n",
      "received tweet # 298\n",
      "received tweet # 299\n",
      "received tweet # 300\n",
      "received tweet # 301\n",
      "received tweet # 302\n",
      "received tweet # 303\n",
      "received tweet # 304\n",
      "received tweet # 305\n",
      "received tweet # 306\n",
      "received tweet # 307\n",
      "received tweet # 308\n",
      "received tweet # 309\n",
      "received tweet # 310\n",
      "received tweet # 311\n",
      "received tweet # 312\n",
      "received tweet # 313\n",
      "received tweet # 314\n",
      "received tweet # 315\n",
      "received tweet # 316\n",
      "received tweet # 317\n",
      "received tweet # 318\n",
      "received tweet # 319\n",
      "received tweet # 320\n",
      "received tweet # 321\n",
      "received tweet # 322\n",
      "received tweet # 323\n",
      "received tweet # 324\n",
      "received tweet # 325\n",
      "received tweet # 326\n",
      "received tweet # 327\n",
      "received tweet # 328\n",
      "received tweet # 329\n",
      "received tweet # 330\n",
      "received tweet # 331\n",
      "received tweet # 332\n",
      "received tweet # 333\n",
      "received tweet # 334\n",
      "received tweet # 335\n",
      "received tweet # 336\n",
      "received tweet # 337\n",
      "received tweet # 338\n",
      "received tweet # 339\n",
      "received tweet # 340\n",
      "received tweet # 341\n",
      "received tweet # 342\n",
      "received tweet # 343\n",
      "received tweet # 344\n",
      "received tweet # 345\n",
      "received tweet # 346\n",
      "received tweet # 347\n",
      "received tweet # 348\n",
      "received tweet # 349\n",
      "received tweet # 350\n",
      "received tweet # 351\n",
      "received tweet # 352\n",
      "received tweet # 353\n",
      "received tweet # 354\n",
      "received tweet # 355\n",
      "received tweet # 356\n",
      "received tweet # 357\n",
      "received tweet # 358\n",
      "received tweet # 359\n",
      "received tweet # 360\n",
      "received tweet # 361\n",
      "received tweet # 362\n",
      "received tweet # 363\n",
      "received tweet # 364\n",
      "received tweet # 365\n",
      "received tweet # 366\n",
      "received tweet # 367\n",
      "received tweet # 368\n",
      "received tweet # 369\n",
      "received tweet # 370\n",
      "received tweet # 371\n",
      "received tweet # 372\n",
      "received tweet # 373\n",
      "received tweet # 374\n",
      "received tweet # 375\n",
      "received tweet # 376\n",
      "received tweet # 377\n",
      "received tweet # 378\n",
      "received tweet # 379\n",
      "received tweet # 380\n",
      "received tweet # 381\n",
      "received tweet # 382\n",
      "received tweet # 383\n",
      "received tweet # 384\n",
      "received tweet # 385\n",
      "received tweet # 386\n",
      "received tweet # 387\n",
      "received tweet # 388\n",
      "received tweet # 389\n",
      "received tweet # 390\n",
      "received tweet # 391\n",
      "received tweet # 392\n",
      "received tweet # 393\n",
      "received tweet # 394\n",
      "received tweet # 395\n",
      "received tweet # 396\n",
      "received tweet # 397\n",
      "received tweet # 398\n",
      "received tweet # 399\n",
      "received tweet # 400\n",
      "received tweet # 401\n",
      "received tweet # 402\n",
      "received tweet # 403\n",
      "received tweet # 404\n",
      "received tweet # 405\n",
      "received tweet # 406\n",
      "received tweet # 407\n",
      "received tweet # 408\n",
      "received tweet # 409\n",
      "received tweet # 410\n",
      "received tweet # 411\n",
      "received tweet # 412\n",
      "received tweet # 413\n",
      "received tweet # 414\n",
      "received tweet # 415\n",
      "received tweet # 416\n",
      "received tweet # 417\n",
      "received tweet # 418\n",
      "received tweet # 419\n",
      "received tweet # 420\n",
      "received tweet # 421\n",
      "received tweet # 422\n",
      "received tweet # 423\n",
      "received tweet # 424\n",
      "received tweet # 425\n",
      "received tweet # 426\n",
      "received tweet # 427\n",
      "received tweet # 428\n",
      "received tweet # 429\n",
      "received tweet # 430\n",
      "received tweet # 431\n",
      "received tweet # 432\n",
      "received tweet # 433\n",
      "received tweet # 434\n",
      "received tweet # 435\n",
      "received tweet # 436\n",
      "received tweet # 437\n",
      "received tweet # 438\n",
      "received tweet # 439\n",
      "received tweet # 440\n",
      "received tweet # 441\n",
      "received tweet # 442\n",
      "received tweet # 443\n",
      "received tweet # 444\n",
      "received tweet # 445\n",
      "received tweet # 446\n",
      "received tweet # 447\n",
      "received tweet # 448\n",
      "received tweet # 449\n",
      "received tweet # 450\n",
      "received tweet # 451\n",
      "received tweet # 452\n",
      "received tweet # 453\n",
      "received tweet # 454\n",
      "received tweet # 455\n",
      "received tweet # 456\n",
      "received tweet # 457\n",
      "received tweet # 458\n",
      "received tweet # 459\n",
      "received tweet # 460\n",
      "received tweet # 461\n",
      "received tweet # 462\n",
      "received tweet # 463\n",
      "received tweet # 464\n",
      "received tweet # 465\n",
      "received tweet # 466\n",
      "received tweet # 467\n",
      "received tweet # 468\n",
      "received tweet # 469\n",
      "received tweet # 470\n",
      "received tweet # 471\n",
      "received tweet # 472\n",
      "received tweet # 473\n",
      "received tweet # 474\n",
      "received tweet # 475\n",
      "received tweet # 476\n",
      "received tweet # 477\n",
      "received tweet # 478\n",
      "received tweet # 479\n",
      "received tweet # 480\n",
      "received tweet # 481\n",
      "received tweet # 482\n",
      "received tweet # 483\n",
      "received tweet # 484\n",
      "received tweet # 485\n",
      "received tweet # 486\n",
      "received tweet # 487\n",
      "received tweet # 488\n",
      "received tweet # 489\n",
      "received tweet # 490\n",
      "received tweet # 491\n",
      "received tweet # 492\n",
      "received tweet # 493\n",
      "received tweet # 494\n",
      "received tweet # 495\n",
      "received tweet # 496\n",
      "received tweet # 497\n",
      "received tweet # 498\n",
      "received tweet # 499\n",
      "received tweet # 500\n",
      "received tweet # 501\n",
      "received tweet # 502\n",
      "received tweet # 503\n",
      "received tweet # 504\n",
      "received tweet # 505\n",
      "received tweet # 506\n",
      "received tweet # 507\n",
      "received tweet # 508\n",
      "received tweet # 509\n",
      "received tweet # 510\n",
      "received tweet # 511\n",
      "received tweet # 512\n",
      "received tweet # 513\n",
      "received tweet # 514\n",
      "received tweet # 515\n",
      "received tweet # 516\n",
      "received tweet # 517\n",
      "received tweet # 518\n",
      "received tweet # 519\n",
      "received tweet # 520\n",
      "received tweet # 521\n",
      "received tweet # 522\n",
      "received tweet # 523\n",
      "received tweet # 524\n",
      "received tweet # 525\n",
      "received tweet # 526\n",
      "received tweet # 527\n",
      "received tweet # 528\n",
      "received tweet # 529\n",
      "received tweet # 530\n",
      "received tweet # 531\n",
      "received tweet # 532\n",
      "received tweet # 533\n",
      "received tweet # 534\n",
      "received tweet # 535\n",
      "received tweet # 536\n",
      "received tweet # 537\n",
      "received tweet # 538\n",
      "received tweet # 539\n",
      "received tweet # 540\n",
      "received tweet # 541\n",
      "received tweet # 542\n",
      "received tweet # 543\n",
      "received tweet # 544\n",
      "received tweet # 545\n",
      "received tweet # 546\n",
      "received tweet # 547\n",
      "received tweet # 548\n",
      "received tweet # 549\n",
      "received tweet # 550\n",
      "received tweet # 551\n",
      "received tweet # 552\n",
      "received tweet # 553\n",
      "received tweet # 554\n",
      "received tweet # 555\n",
      "received tweet # 556\n",
      "received tweet # 557\n",
      "received tweet # 558\n",
      "received tweet # 559\n",
      "received tweet # 560\n",
      "received tweet # 561\n",
      "received tweet # 562\n",
      "received tweet # 563\n",
      "received tweet # 564\n",
      "received tweet # 565\n",
      "received tweet # 566\n",
      "received tweet # 567\n",
      "received tweet # 568\n",
      "received tweet # 569\n",
      "received tweet # 570\n",
      "received tweet # 571\n",
      "received tweet # 572\n",
      "received tweet # 573\n",
      "received tweet # 574\n",
      "received tweet # 575\n",
      "received tweet # 576\n",
      "received tweet # 577\n",
      "received tweet # 578\n",
      "received tweet # 579\n",
      "received tweet # 580\n",
      "received tweet # 581\n",
      "received tweet # 582\n",
      "received tweet # 583\n",
      "received tweet # 584\n",
      "received tweet # 585\n",
      "received tweet # 586\n",
      "received tweet # 587\n",
      "received tweet # 588\n",
      "received tweet # 589\n",
      "received tweet # 590\n",
      "received tweet # 591\n",
      "received tweet # 592\n",
      "received tweet # 593\n",
      "received tweet # 594\n",
      "received tweet # 595\n",
      "received tweet # 596\n",
      "received tweet # 597\n",
      "received tweet # 598\n",
      "received tweet # 599\n",
      "received tweet # 600\n",
      "received tweet # 601\n",
      "received tweet # 602\n",
      "received tweet # 603\n",
      "received tweet # 604\n",
      "received tweet # 605\n",
      "received tweet # 606\n",
      "received tweet # 607\n",
      "received tweet # 608\n",
      "received tweet # 609\n",
      "received tweet # 610\n",
      "received tweet # 611\n",
      "received tweet # 612\n",
      "received tweet # 613\n",
      "received tweet # 614\n",
      "received tweet # 615\n",
      "received tweet # 616\n",
      "received tweet # 617\n",
      "received tweet # 618\n",
      "received tweet # 619\n",
      "received tweet # 620\n",
      "received tweet # 621\n",
      "received tweet # 622\n",
      "received tweet # 623\n",
      "received tweet # 624\n",
      "received tweet # 625\n",
      "received tweet # 626\n",
      "received tweet # 627\n",
      "received tweet # 628\n",
      "received tweet # 629\n",
      "received tweet # 630\n",
      "received tweet # 631\n",
      "received tweet # 632\n",
      "received tweet # 633\n",
      "received tweet # 634\n",
      "received tweet # 635\n",
      "received tweet # 636\n",
      "received tweet # 637\n",
      "received tweet # 638\n",
      "received tweet # 639\n",
      "received tweet # 640\n",
      "received tweet # 641\n",
      "received tweet # 642\n",
      "received tweet # 643\n",
      "received tweet # 644\n",
      "received tweet # 645\n",
      "received tweet # 646\n",
      "received tweet # 647\n",
      "received tweet # 648\n",
      "received tweet # 649\n",
      "received tweet # 650\n",
      "received tweet # 651\n",
      "received tweet # 652\n",
      "received tweet # 653\n",
      "received tweet # 654\n",
      "received tweet # 655\n",
      "received tweet # 656\n",
      "received tweet # 657\n",
      "received tweet # 658\n",
      "received tweet # 659\n",
      "received tweet # 660\n",
      "received tweet # 661\n",
      "received tweet # 662\n",
      "received tweet # 663\n",
      "received tweet # 664\n",
      "received tweet # 665\n",
      "received tweet # 666\n",
      "received tweet # 667\n",
      "received tweet # 668\n",
      "received tweet # 669\n",
      "received tweet # 670\n",
      "received tweet # 671\n",
      "received tweet # 672\n",
      "received tweet # 673\n",
      "received tweet # 674\n",
      "received tweet # 675\n",
      "received tweet # 676\n",
      "received tweet # 677\n",
      "received tweet # 678\n",
      "received tweet # 679\n",
      "received tweet # 680\n",
      "received tweet # 681\n",
      "received tweet # 682\n",
      "received tweet # 683\n",
      "received tweet # 684\n",
      "received tweet # 685\n",
      "received tweet # 686\n",
      "received tweet # 687\n",
      "received tweet # 688\n",
      "received tweet # 689\n",
      "received tweet # 690\n",
      "received tweet # 691\n",
      "received tweet # 692\n",
      "received tweet # 693\n",
      "received tweet # 694\n",
      "received tweet # 695\n",
      "received tweet # 696\n",
      "received tweet # 697\n",
      "received tweet # 698\n",
      "received tweet # 699\n",
      "received tweet # 700\n",
      "received tweet # 701\n",
      "received tweet # 702\n",
      "received tweet # 703\n",
      "received tweet # 704\n",
      "received tweet # 705\n",
      "received tweet # 706\n",
      "received tweet # 707\n",
      "received tweet # 708\n",
      "received tweet # 709\n",
      "received tweet # 710\n",
      "received tweet # 711\n",
      "received tweet # 712\n",
      "received tweet # 713\n",
      "received tweet # 714\n",
      "received tweet # 715\n",
      "received tweet # 716\n",
      "received tweet # 717\n",
      "received tweet # 718\n",
      "received tweet # 719\n",
      "received tweet # 720\n",
      "received tweet # 721\n",
      "received tweet # 722\n",
      "received tweet # 723\n",
      "received tweet # 724\n",
      "received tweet # 725\n",
      "received tweet # 726\n",
      "received tweet # 727\n",
      "received tweet # 728\n",
      "received tweet # 729\n",
      "received tweet # 730\n",
      "received tweet # 731\n",
      "received tweet # 732\n",
      "received tweet # 733\n",
      "received tweet # 734\n",
      "received tweet # 735\n",
      "received tweet # 736\n",
      "received tweet # 737\n",
      "received tweet # 738\n",
      "received tweet # 739\n",
      "received tweet # 740\n",
      "received tweet # 741\n",
      "received tweet # 742\n",
      "received tweet # 743\n",
      "received tweet # 744\n",
      "received tweet # 745\n",
      "received tweet # 746\n",
      "received tweet # 747\n",
      "received tweet # 748\n",
      "received tweet # 749\n",
      "received tweet # 750\n",
      "received tweet # 751\n",
      "received tweet # 752\n",
      "received tweet # 753\n",
      "received tweet # 754\n",
      "received tweet # 755\n",
      "received tweet # 756\n",
      "received tweet # 757\n",
      "received tweet # 758\n",
      "received tweet # 759\n",
      "received tweet # 760\n",
      "received tweet # 761\n",
      "received tweet # 762\n",
      "received tweet # 763\n",
      "received tweet # 764\n",
      "received tweet # 765\n",
      "received tweet # 766\n",
      "received tweet # 767\n",
      "received tweet # 768\n",
      "received tweet # 769\n",
      "received tweet # 770\n",
      "received tweet # 771\n",
      "received tweet # 772\n",
      "received tweet # 773\n",
      "received tweet # 774\n",
      "received tweet # 775\n",
      "received tweet # 776\n",
      "received tweet # 777\n",
      "received tweet # 778\n",
      "received tweet # 779\n",
      "received tweet # 780\n",
      "received tweet # 781\n",
      "received tweet # 782\n",
      "received tweet # 783\n",
      "received tweet # 784\n",
      "received tweet # 785\n",
      "received tweet # 786\n",
      "received tweet # 787\n",
      "received tweet # 788\n",
      "received tweet # 789\n",
      "received tweet # 790\n",
      "received tweet # 791\n",
      "received tweet # 792\n",
      "received tweet # 793\n",
      "received tweet # 794\n",
      "received tweet # 795\n",
      "received tweet # 796\n",
      "received tweet # 797\n",
      "received tweet # 798\n",
      "received tweet # 799\n",
      "received tweet # 800\n",
      "received tweet # 801\n",
      "received tweet # 802\n",
      "received tweet # 803\n",
      "received tweet # 804\n",
      "received tweet # 805\n",
      "received tweet # 806\n",
      "received tweet # 807\n",
      "received tweet # 808\n",
      "received tweet # 809\n",
      "received tweet # 810\n",
      "received tweet # 811\n",
      "received tweet # 812\n",
      "received tweet # 813\n",
      "received tweet # 814\n",
      "received tweet # 815\n",
      "received tweet # 816\n",
      "received tweet # 817\n",
      "received tweet # 818\n",
      "received tweet # 819\n",
      "received tweet # 820\n",
      "received tweet # 821\n",
      "received tweet # 822\n",
      "received tweet # 823\n",
      "received tweet # 824\n",
      "received tweet # 825\n",
      "received tweet # 826\n",
      "received tweet # 827\n",
      "received tweet # 828\n",
      "received tweet # 829\n",
      "received tweet # 830\n",
      "received tweet # 831\n",
      "received tweet # 832\n",
      "received tweet # 833\n",
      "received tweet # 834\n",
      "received tweet # 835\n",
      "received tweet # 836\n",
      "received tweet # 837\n",
      "received tweet # 838\n",
      "received tweet # 839\n",
      "received tweet # 840\n",
      "received tweet # 841\n",
      "received tweet # 842\n",
      "received tweet # 843\n",
      "received tweet # 844\n",
      "received tweet # 845\n",
      "received tweet # 846\n",
      "received tweet # 847\n",
      "received tweet # 848\n",
      "received tweet # 849\n",
      "received tweet # 850\n",
      "received tweet # 851\n",
      "received tweet # 852\n",
      "received tweet # 853\n",
      "received tweet # 854\n",
      "received tweet # 855\n",
      "received tweet # 856\n",
      "received tweet # 857\n",
      "received tweet # 858\n",
      "received tweet # 859\n",
      "received tweet # 860\n",
      "received tweet # 861\n",
      "received tweet # 862\n",
      "received tweet # 863\n",
      "received tweet # 864\n",
      "received tweet # 865\n",
      "received tweet # 866\n",
      "received tweet # 867\n",
      "received tweet # 868\n",
      "received tweet # 869\n",
      "received tweet # 870\n",
      "received tweet # 871\n",
      "received tweet # 872\n",
      "received tweet # 873\n",
      "received tweet # 874\n",
      "received tweet # 875\n",
      "received tweet # 876\n",
      "received tweet # 877\n",
      "received tweet # 878\n",
      "received tweet # 879\n",
      "received tweet # 880\n",
      "received tweet # 881\n",
      "received tweet # 882\n",
      "received tweet # 883\n",
      "received tweet # 884\n",
      "received tweet # 885\n",
      "received tweet # 886\n",
      "received tweet # 887\n",
      "received tweet # 888\n",
      "received tweet # 889\n",
      "received tweet # 890\n",
      "received tweet # 891\n",
      "received tweet # 892\n",
      "received tweet # 893\n",
      "received tweet # 894\n",
      "received tweet # 895\n",
      "received tweet # 896\n",
      "received tweet # 897\n",
      "received tweet # 898\n",
      "received tweet # 899\n",
      "received tweet # 900\n",
      "received tweet # 901\n",
      "received tweet # 902\n",
      "received tweet # 903\n",
      "received tweet # 904\n",
      "received tweet # 905\n",
      "received tweet # 906\n",
      "received tweet # 907\n",
      "received tweet # 908\n",
      "received tweet # 909\n",
      "received tweet # 910\n",
      "received tweet # 911\n",
      "received tweet # 912\n",
      "received tweet # 913\n",
      "received tweet # 914\n",
      "received tweet # 915\n",
      "received tweet # 916\n",
      "received tweet # 917\n",
      "received tweet # 918\n",
      "received tweet # 919\n",
      "received tweet # 920\n",
      "received tweet # 921\n",
      "received tweet # 922\n",
      "received tweet # 923\n",
      "received tweet # 924\n",
      "received tweet # 925\n",
      "received tweet # 926\n",
      "received tweet # 927\n",
      "received tweet # 928\n",
      "received tweet # 929\n",
      "received tweet # 930\n",
      "received tweet # 931\n",
      "received tweet # 932\n",
      "received tweet # 933\n",
      "received tweet # 934\n",
      "received tweet # 935\n",
      "received tweet # 936\n",
      "received tweet # 937\n",
      "received tweet # 938\n",
      "received tweet # 939\n",
      "received tweet # 940\n",
      "received tweet # 941\n",
      "received tweet # 942\n",
      "received tweet # 943\n",
      "received tweet # 944\n",
      "received tweet # 945\n",
      "received tweet # 946\n",
      "received tweet # 947\n",
      "received tweet # 948\n",
      "received tweet # 949\n",
      "received tweet # 950\n",
      "received tweet # 951\n",
      "received tweet # 952\n",
      "received tweet # 953\n",
      "received tweet # 954\n",
      "received tweet # 955\n",
      "received tweet # 956\n",
      "received tweet # 957\n",
      "received tweet # 958\n",
      "received tweet # 959\n",
      "received tweet # 960\n",
      "received tweet # 961\n",
      "received tweet # 962\n",
      "received tweet # 963\n",
      "received tweet # 964\n",
      "received tweet # 965\n",
      "received tweet # 966\n",
      "received tweet # 967\n",
      "received tweet # 968\n",
      "received tweet # 969\n",
      "received tweet # 970\n",
      "received tweet # 971\n",
      "received tweet # 972\n",
      "received tweet # 973\n",
      "received tweet # 974\n",
      "received tweet # 975\n",
      "received tweet # 976\n",
      "received tweet # 977\n",
      "received tweet # 978\n",
      "received tweet # 979\n",
      "received tweet # 980\n",
      "received tweet # 981\n",
      "received tweet # 982\n",
      "received tweet # 983\n",
      "received tweet # 984\n",
      "received tweet # 985\n",
      "received tweet # 986\n",
      "received tweet # 987\n",
      "received tweet # 988\n",
      "received tweet # 989\n",
      "received tweet # 990\n",
      "received tweet # 991\n",
      "received tweet # 992\n",
      "received tweet # 993\n",
      "received tweet # 994\n",
      "received tweet # 995\n",
      "received tweet # 996\n",
      "received tweet # 997\n",
      "received tweet # 998\n",
      "received tweet # 999\n",
      "received tweet # 1000\n"
     ]
    }
   ],
   "source": [
    "with open('credentials.json') as json_data:\n",
    "    credentials = json.load(json_data)\n",
    "    consumer_key = credentials[0][\"CONSUMER_KEY\"]\n",
    "    consumer_secret = credentials[0][\"CONSUMER_SECRET\"]\n",
    "    access_token = credentials[0][\"ACCESS_TOKEN\"]\n",
    "    access_token_secret = credentials[0][\"ACCESS_TOKEN_SECRET\"]\n",
    "    \n",
    "stream = MyStreamer(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "# start consuming public statuses that contain the keyword 'data'\n",
    "stream.statuses.filter(track='data')\n",
    "# if instead we want to start sampling *all* public statuses, use stream.statuses.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will run until it collects 1000 tweets or throws an error, so go get some coffee and check your email.  \n",
    "Once all that is finished, the user can start analyzing those tweets.  \n",
    "For example, finding the most common hashtags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'data', 47), (u'analytics', 35), (u'bigdata', 34), (u'obamalegacy', 12), (u'ogp16', 10)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "top_hashtags = Counter(hashtag['text'].lower()\n",
    "                       for tweet in tweets\n",
    "                       for hashtag in tweet[\"entities\"][\"hashtags\"])\n",
    "\n",
    "print top_hashtags.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tweet contains a lot of data.  \n",
    "Feel free to explore the data as well as the [Twitter API documentation](https://dev.twitter.com/overview/api/tweets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Further Exploration\n",
    "- [pandas](http://pandas.pydata.org/)\n",
    "- [Scrapy](https://scrapy.org/) is a more full-featured library for building sophisticated web scrapers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
